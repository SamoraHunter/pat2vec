{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def generate_client_ids(n=10):\n",
    "    \"\"\"Generate n random 10-digit client ID strings.\"\"\"\n",
    "    ids = []\n",
    "    for _ in range(n):\n",
    "        # Ensure it's exactly 10 digits (no leading digit loss)\n",
    "        id_code = ''.join(str(random.randint(0, 9)) for _ in range(10))\n",
    "        ids.append(id_code)\n",
    "    return ids\n",
    "\n",
    "# Number of entries (default = 10)\n",
    "n = 10\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"client_idcode\": generate_client_ids(n)\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"treatment_docs.csv\", index=False)\n",
    "\n",
    "print(\"CSV file 'treatment_docs.csv' created!\")\n",
    "print(df.head())\n",
    "\n",
    "# Replace this with your cohort (Hospital numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "# Fix the random seed for reproducibility in unit testing\n",
    "\n",
    "random_seed_value = 42\n",
    "\n",
    "np.random.seed(random_seed_value)\n",
    "\n",
    "random.seed(random_seed_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Print the current working directory\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "# 2. Print Python's sys.path\n",
    "print(\"Python Path:\", sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dir\n",
    "clear_previous_outputs = True\n",
    "\n",
    "if(clear_previous_outputs):\n",
    "\n",
    "    shutil.rmtree('new_project', ignore_errors=True)\n",
    "\n",
    "    shutil.rmtree('new_project_ipw', ignore_errors=True)\n",
    "\n",
    "    shutil.rmtree('treatment_doc_extract', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dependencies are on path\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define relative paths from the current working directory\n",
    "path_to_medcat_model_pack = os.path.abspath(os.path.join(current_dir, '..', '..', 'medcat_models', 'medcat_model_pack_422d1d38fc58f158.zip'))\n",
    "\n",
    "path_to_snomed_ct_file = os.path.abspath(os.path.join(current_dir, '..', '..', 'snomed', 'SnomedCT_InternationalRF2_PRODUCTION_20231101T120000Z', 'SnomedCT_InternationalRF2_PRODUCTION_20231101T120000Z', 'Full', 'Terminology', 'sct2_StatedRelationship_Full_INT_20231101.txt'))\n",
    "\n",
    " # Define the relative path\n",
    "path_to_gloabl_files = '../../'\n",
    "\n",
    "additional_path_to_pat2vec = 'pat2vec'\n",
    "\n",
    "additional_path_to_pat2vec = os.path.abspath(os.path.join(path_to_gloabl_files, additional_path_to_pat2vec))\n",
    "\n",
    "# Get the absolute path of the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Combine the current directory with the relative path\n",
    "absolute_path = os.path.abspath(os.path.join(current_dir, path_to_gloabl_files))\n",
    "\n",
    "# Usage examples\n",
    "print(path_to_medcat_model_pack)\n",
    "print(path_to_snomed_ct_file)\n",
    "print(path_to_gloabl_files)\n",
    "print(additional_path_to_pat2vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, path_to_gloabl_files)\n",
    "sys.path.insert(0, additional_path_to_pat2vec)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Add the grandparent directory of the current directory to the Python path\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "sys.path.append(grandparent_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pat2vec.util.logger_setup import setup_logger\n",
    "\n",
    "# Get the logger\n",
    "logger = setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pat2vec.util.config_pat2vec import config_class\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from pat2vec.util.post_processing_process_csv_files import process_csv_files \n",
    "from pat2vec.util.post_processing import extract_datetime_to_column\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "# Configuration dictionary for main options in pat2vec\n",
    "main_options_dict = {\n",
    "    \n",
    "    'demo': True, # Enable demographic information (Ethnicity mapped to UK census categories, age, death).\n",
    "    'bmi': True,  # Enable BMI (Body Mass Index) information.\n",
    "    'bloods': True,  # Enable blood-related information\n",
    "    'drugs': True,  # Enable drug-related information\n",
    "    'diagnostics': True,  # Enable diagnostic information\n",
    "\n",
    "    'core_02': True,  # Enable core_02 information\n",
    "    'bed': True,  # Enable bed n information\n",
    "    'vte_status': True,  # Enable VTE () status information\n",
    "    'hosp_site': True,  # Enable hospital site information\n",
    "    'core_resus': True,  # Enable core resuscitation information\n",
    "    'news': True,  # Enable NEWS (National Early Warning Score) information\n",
    "\n",
    "    'smoking': True,  # Enable smoking-related information\n",
    "    'annotations': True,  # Enable EPR documents annotations via MedCat\n",
    "    'annotations_mrc': True,# Enable MRC (Additional clinical note observations index) annotations via MedCat\n",
    "    'negated_presence_annotations': False, # Enable or disable negated presence annotations\n",
    "    'appointments': False,  # Enable appointments information\n",
    "    'annotations_reports': False,  # Enable reports information\n",
    "    'textual_obs': False,  # Enable textual observations (basic_observations index) annotations via MedCat\n",
    "}\n",
    "\n",
    "# Configuration dictionary for annotation filtering, only base annotations meeting this threshold will be included.\n",
    "annot_filter_arguments = {\n",
    "    'acc': 0.8,  # base concept accuracy\n",
    "    'types': ['qualifier value', 'procedure', 'substance', 'finding', 'environment', 'disorder', 'observable entity'], # umls list of types for medcat filter\n",
    "    # 'types': ['qualifier value', 'procedure', 'substance', 'finding', 'environment', 'disorder', 'observable entity', 'organism', 'phenomenon', 'anatomy', 'conceptual entity', 'physical object', 'intellectual product', 'occupation or discipline', 'mental or behavioral dysfunction', 'geographic area', 'population group', 'biomedical or dental material', 'medical device', 'classification', 'regulation or law', 'health care activity', 'health care related organization', 'professional or occupational group', 'group', 'attribute', 'individual behavior']\n",
    "    \n",
    "    'Time_Value': ['Recent', 'Past'], # Specify the values you want to include in a list. Must be defined in medcat model. # Example ['Recent', 'Past', 'Subject/Experiencer']\n",
    "    'Time_Confidence': 0.8,  # Specify the confidence threshold as a float\n",
    "    'Presence_Value': ['True'], # Specify the values you want to include in a list\n",
    "    'Presence_Confidence': 0.8,  # Specify the confidence threshold as a float\n",
    "    'Subject_Value': ['Patient'], # Specify the values you want to include in a list\n",
    "    'Subject_Confidence': 0.8  # Specify the confidence threshold as a float\n",
    "}\n",
    "\n",
    "# Filter data batches by terms before processing. \n",
    "\n",
    "epr_docs_term_regex: Optional[Union[str, None]] = None\n",
    "mct_docs_term_regex: Optional[Union[str, None]] = None\n",
    "\n",
    "# Example bloods_filter_term_list: Optional[Union[List[str], None]] = ['wbc'] # This will only include basic observations with this item name analysed.\n",
    "bloods_filter_term_list: Optional[Union[List[str], None]] = None\n",
    "\n",
    "# Example mct_docs_document_type_filter_list: Optional[Union[List[str], None]] = ['KHMDC Integrated report'] # This will only include documents with this document type field value.\n",
    "\n",
    "mct_docs_document_type_filter_list: Optional[Union[List[str], None]] = None\n",
    "epr_docs_document_type_filter_list: Optional[Union[List[str], None]] = None\n",
    "\n",
    "data_type_filter_dict: Dict[str, any] = {\n",
    "    'filter_term_lists': {\n",
    "        'epr_docs': epr_docs_document_type_filter_list,\n",
    "        'mct_docs': mct_docs_document_type_filter_list,\n",
    "        'bloods': bloods_filter_term_list\n",
    "    },\n",
    "    'epr_docs_term_regex': epr_docs_term_regex,\n",
    "    'mct_docs_term_regex': mct_docs_term_regex,\n",
    "}\n",
    "\n",
    "#Example date settings:\n",
    "#start_date=(datetime(2020, 1, 1)) Start date for processing\n",
    "\n",
    "# Define the length of the time window, example 1 year and 15 days, only data within this window will be processed.\n",
    "# years=1,      # Number of years to add to the start date \n",
    "# months=0,  # Number of months to add to the start date\n",
    "# days=15,  # Number of days to add to the start date\n",
    "\n",
    "# Define the interval between time windows. Example 1 year. Each vector/row output will be based on this interval.\n",
    "# time_window_interval_delta = relativedelta(years=1)\n",
    "\n",
    "# lookback = True #This determines the direction of the time length window. True = backward, False = forward. Our time window (+1 years, 15 days) is therefore 2020, 1, 1 - 2021, 1, 15. \n",
    "\n",
    "# IPW settings:\n",
    "\n",
    "# Init config obj\n",
    "\n",
    "# Hypothetical date config_obj configuration:\n",
    "# I want all patients data between Feb 2015 and Jul 2020. This date window will extract and create the batched patient data for this time window.\n",
    "\n",
    "# global_start_year=2015, \n",
    "# global_start_month=2,  \n",
    "# global_end_year=2020,  \n",
    "# global_end_month=6, \n",
    "# global_start_day = 1, \n",
    "# global_end_day = 1, \n",
    "\n",
    "# I want patient vectors starting from Feb 2019 to Feb 2020 as I would like to see if X medical event is recorded on those taking medication Y\n",
    "# start_date=(datetime(2019, 2, 1)),  \n",
    "# years=1, \n",
    "# months=0,  \n",
    "# days=0, \n",
    "# lookback = False # 2019 to 2020 is forward in time.\n",
    "# I would like a single vector for each patient\n",
    "# time_window_interval_delta = relativedelta(years=1) \n",
    "# I would like 1 vector per month per patient for the 1 year time window\n",
    "# time_window_interval_delta = relativedelta(months=1)\n",
    "\n",
    "# Creating a configuration object for a specific task or project\n",
    "config_obj = config_class(\n",
    "    remote_dump=False,  # Flag for remote data dumping. partially deprecated.\n",
    "    suffix='',  # Suffix for file names\n",
    "    treatment_doc_filename='test_files/treatment_docs.csv', # Filename for treatment documentation\n",
    "    treatment_control_ratio_n=1,  # Ratio for treatment to control\n",
    "    proj_name='new_project', # Project name. patient data batches and vectors stored here.\n",
    "    current_path_dir=\"\",  # Current path directory\n",
    "    main_options=main_options_dict,  # Dictionary for main options\n",
    "    start_date=(datetime(1995, 1, 1)),  # Starting date for processing\n",
    "    years=30, # Number of years to add to the start date. Set the duration of the time window. Window is defined as the start date + years/months/days set here.\n",
    "    months=0,  # Number of months to add to the start date\n",
    "    days=0,  # Number of days to add to the start date\n",
    "    batch_mode=True,  # Flag for batch processing mode. Only functioning mode.\n",
    "    store_annot=True,  # Flag to store annotations. partially deprecated.\n",
    "    share_sftp=True,  # Flag for sharing via SFTP. partially deprecated\n",
    "    multi_process=False,  # Flag for multi-process execution. deprecated.\n",
    "    strip_list=True, # Flag for stripping lists, this will check for completed patients before starting to avoid redundancy.\n",
    "    verbosity=0,  # Verbosity level 0-9 printing debug messages\n",
    "    random_seed_val=random_seed_value,  # Random seed value for reproducibility of controls.\n",
    "    testing=True,  # Flag for testing mode. Will use dummy data.\n",
    "    dummy_medcat_model=True,  # Flag for dummy MedCAT model, used if testing == True, this will simulate a MedCAT model.\n",
    "    use_controls=False, # If true this will add desired ratio of controls at random from global pool, requires configuring with a master list of patients.\n",
    "    medcat=False, # Flag for MedCAT processing. #will load medcat into memory and use for annotating.\n",
    "    start_time=datetime.now(), # Current timestamp as the start time for logging and progress bar\n",
    "    patient_id_column_name='auto', # Column name for patient ID, auto will try to find it. Example \"client_idcode\"\n",
    "    annot_filter_options=annot_filter_arguments,  # Annotation filtering options\n",
    "    \n",
    "    # Global start year. #set the limits of the time window data can be drawn from. Start should not precede start date set above.\n",
    "    global_start_year=1995, # Global dates are overwritten by individual patient windows to match patient window. # Ensure that global start year/month/day is before end year/month/day\n",
    "    global_start_month=1,  # Global start month\n",
    "    global_end_year=2025,  # Global end year\n",
    "    global_end_month=1, # Global end month\n",
    "    global_start_day = 1, \n",
    "    global_end_day = 1, \n",
    "    ## Use these if each patient has their own individual time window. Requires preparing a table of start dates.\n",
    "    # individual_patient_window = True,\n",
    "    # individual_patient_window_df = pd.read_csv('ipw_overlap.csv'),\n",
    "    # individual_patient_window_start_column_name = 'updatetime_manual_offset',\n",
    "    # individual_patient_id_column_name = 'client_idcode',\n",
    "    # individual_patient_window_controls_method = 'full',\n",
    "    shuffle_pat_list=False,  # Flag for shuffling patient list\n",
    "    time_window_interval_delta = relativedelta(years=31), #specify the time window to collapse each feature vector into, years=1 is one vector per year within the global time window\n",
    "    split_clinical_notes=True, #will split clinical notes by date and treat as individual documents with extracted dates. Requires note splitter module. \n",
    "    lookback = False, # when calculating individual patient window from table of start dates, will calculate backwards in time if true. Else Forwards. When calculating from global start date, will calculate backwards or forwards respectively. \n",
    "    add_icd10 = False, #append icd 10 codes to annot batches. Can be found under current_pat_documents_annotations/%client_idcode%.csv.\n",
    "    add_opc4s=False, # needs icd10 true also. Can be found under current_pat_documents_annotations/%client_idcode%.csv\n",
    "    override_medcat_model_path = path_to_medcat_model_pack, #Force medcat model path, if None uses defaults for env. #Can be set in paths.py with medcat_path = %path to medcat model pack.zip\"\n",
    "    data_type_filter_dict = None, # Dictionary for data type filter, see examples above. \n",
    "    filter_split_notes = True, # If enabled, will reapply global time window filter post clinical note splitting. Recommended to enable if split notes enabled.\n",
    "    prefetch_pat_batches = False, # If enabled, will fetch batches for entire patient list and pre poulate batch folders with individual pat batches. Out of memory issues.\n",
    "    sample_treatment_docs=5 # If int > 0, will sample treatment documents from the treatment_docs.csv file. This is useful for testing and debugging / pilot run purposes.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pat2vec.main_pat2vec import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat2vec_obj = main( cogstack=True, use_filter=False,\n",
    "             json_filter_path = None, random_seed_val=42, \n",
    "             hostname =None, config_obj= config_obj, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat2vec_obj.all_patient_list[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat2vec_obj.config_obj.date_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pat vectors for pat 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat2vec_obj.pat_maker(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specific patient raw documents and annotations:\n",
    "from pat2vec.util.post_processing import remove_file_from_paths\n",
    "\n",
    "# remove_file_from_paths(pat2vec_obj.all_patient_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the maximum number of retries\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "# Iterate through the patient list starting from index 0\n",
    "for i in tqdm(range(0, len(pat2vec_obj.all_patient_list))):\n",
    "    retries = 0\n",
    "    success = False\n",
    "    \n",
    "    while retries < MAX_RETRIES and not success:\n",
    "        try:\n",
    "            # Try to process the patient\n",
    "            pat2vec_obj.pat_maker(i)\n",
    "            success = True  # Mark as successful if no exception is raised\n",
    "            \n",
    "        except KeyError as e:\n",
    "            # Handle specific exception\n",
    "            print(f\"KeyError at index {i}: {e}. Retrying after removal...\")\n",
    "            remove_file_from_paths(pat2vec_obj.all_patient_list[i])\n",
    "            retries += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Handle generic exceptions\n",
    "            print(f\"Exception at index {i}: {e}. Skipping this patient...\")\n",
    "            break  # Break the retry loop for non-retryable exceptions\n",
    "            \n",
    "        finally:\n",
    "            pat2vec_obj.t.update(1)  # Update progress\n",
    "\n",
    "    if not success:\n",
    "        print(f\"Failed to process index {i} after {MAX_RETRIES} retries.\")\n",
    "\n",
    "pat2vec_obj.t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = f'{pat2vec_obj.proj_name}/current_pat_lines_parts' # Patient vectors are stored individually in this directory. \n",
    "output_csv_file = 'output_file'\n",
    "\n",
    "# Specify the directory where you want to create the file\n",
    "directory = pat2vec_obj.proj_name + '/output_directory'\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# We will join the individual patient vectors into a single output file. This is useful for filtering.\n",
    "output_csv_file_filename = process_csv_files(input_directory, out_folder=directory, output_filename_suffix=output_csv_file, part_size=336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(output_csv_file_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_datetime_to_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build all document batches dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will merge all document source batches into a single file. This is useful for filtering. May produce a large file.\n",
    "\n",
    "from pat2vec.util.post_processing_build_methods import build_merged_epr_mct_doc_df\n",
    "\n",
    "all_pat_list = pat2vec_obj.all_patient_list\n",
    "\n",
    "dfd = build_merged_epr_mct_doc_df(all_pat_list, pat2vec_obj.config_obj, overwrite=True)\n",
    "\n",
    "#dfd = pd.read_csv(dfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build all annotation batches dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will merge all annotation source batches into a single file. This is useful for filtering. May produce a large file.\n",
    "\n",
    "from pat2vec.util.post_processing_build_methods import build_merged_epr_mct_annot_df\n",
    "\n",
    "all_pat_list = pat2vec_obj.all_patient_list\n",
    "\n",
    "dfa = build_merged_epr_mct_annot_df(all_pat_list, pat2vec_obj.config_obj, overwrite=True)\n",
    "\n",
    "dfa = pd.read_csv(dfa)\n",
    "\n",
    "dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build additional batches from individual patient data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will merge all drug source batches into a single file. This is useful for filtering. May produce a large file.\n",
    "\n",
    "from pat2vec.util.post_processing_build_methods import merge_drugs_csv\n",
    "\n",
    "all_pat_list = pat2vec_obj.all_patient_list\n",
    "\n",
    "merged_drugs_path = merge_drugs_csv(all_pat_list, pat2vec_obj.config_obj, overwrite=True)\n",
    "\n",
    "merged_drugs = pd.read_csv(merged_drugs_path)\n",
    "merged_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfmdi = pd.read_csv('new_project/merged_input_pat_batches/merged_drugs_batches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in dfmdi.select_dtypes(exclude=[np.number]).columns:\n",
    "#     assert dfmdi[col].astype(str).equals(merged_drugs[col].astype(str)), f\"Mismatch in column: {col}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will merge all diagnostics source batches into a single file. This is useful for filtering. May produce a large file.\n",
    "\n",
    "from pat2vec.util.post_processing_build_methods import merge_diagnostics_csv\n",
    "\n",
    "all_pat_list = pat2vec_obj.all_patient_list\n",
    "\n",
    "merged_diagnostics_path = merge_diagnostics_csv(all_pat_list, pat2vec_obj.config_obj, overwrite=True)\n",
    "\n",
    "merged_diagnostics = pd.read_csv(merged_diagnostics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pat2vec.util.post_processing_build_methods import merge_news_csv\n",
    "\n",
    "all_pat_list = pat2vec_obj.all_patient_list\n",
    "\n",
    "merged_news_path = merge_news_csv(all_pat_list, pat2vec_obj.config_obj, overwrite=True)\n",
    "\n",
    "#merged_news = pd.read_csv(merged_news_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pat2vec.util.post_processing_build_methods import merge_bmi_csv\n",
    "\n",
    "all_pat_list = pat2vec_obj.all_patient_list\n",
    "\n",
    "merged_bmi_path = merge_bmi_csv(all_pat_list, pat2vec_obj.config_obj, overwrite=True)\n",
    "\n",
    "#merged_bmi = pd.read_csv(merged_bmi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pat2vec.util.post_processing_build_methods import build_merged_bloods\n",
    "\n",
    "all_pat_list = pat2vec_obj.all_patient_list\n",
    "\n",
    "merged_bloods_path = build_merged_bloods(all_pat_list, pat2vec_obj.config_obj, overwrite=True)\n",
    "\n",
    "merged_bloods = pd.read_csv(merged_bloods_path)\n",
    "merged_bloods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv('new_project/merged_input_pat_batches/merged_bloods_batches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pat2vec.util.post_processing_build_methods import merge_demographics_csv\n",
    "\n",
    "all_pat_list = pat2vec_obj.all_patient_list\n",
    "\n",
    "merged_demographics_path = merge_demographics_csv(all_pat_list, pat2vec_obj.config_obj, overwrite=True)\n",
    "\n",
    "merged_demographics = pd.read_csv(merged_demographics_path)\n",
    "\n",
    "merged_demographics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pat2vec_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
