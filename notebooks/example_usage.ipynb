{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure pat2vec is on path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree('new_project')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "sys.path.insert(0,'/home/aliencat/samora/gloabl_files')\n",
    "sys.path.insert(0,'/data/AS/Samora/gloabl_files')\n",
    "sys.path.insert(0,'/home/jovyan/work/gloabl_files')\n",
    "sys.path.insert(0,'/home/cogstack/samora/_data/gloabl_files')\n",
    "sys.path.append('c:\\\\Users\\\\admin\\\\Documents\\\\projects\\\\pat2vec_time\\\\')\n",
    "sys.path.append(r'C:\\Users\\admin\\Documents\\projects\\gloabl_files')\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Add the grandparent directory of the current directory to the Python path\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "sys.path.append(grandparent_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cogstack/samora/_data/gloabl_files/pat2vec/notebooks/new_project/<bound method PathsClass._print_paths of <pat2vec.util.current_pat_batch_path_methods.PathsClass object at 0x7fccd446f6d0>>\n",
      "/home/cogstack/samora/_data/gloabl_files/pat2vec/notebooks/new_project/['current_pat_annots_parts/', 'current_pat_annots_mrc_parts/', 'current_pat_documents_annotations_batches/', 'current_pat_documents_annotations_batches_mct/', 'current_pat_document_batches/', 'current_pat_document_batches_mct/', 'current_pat_bloods_batches/', 'current_pat_drugs_batches/', 'current_pat_diagnostics_batches/', 'current_pat_news_batches/', 'current_pat_obs_batches/', 'current_pat_bmi_batches/', 'current_pat_demo_batches/', 'current_pat_lines_parts/', 'outputs', '/home/cogstack/samora/_data/gloabl_files/pat2vec/notebooks/new_project/outputs']\n",
      "/home/cogstack/samora/_data/gloabl_files/pat2vec/notebooks/new_project/\n",
      "Setting start_date to: 2020-01-01 00:00:00\n",
      "Setting years to: 0\n",
      "Setting months to: 0\n",
      "Setting days to: 2\n",
      "Number of 1-day intervals between 2020-01-01 00:00:00 and the calculated end date: 2\n",
      "looking back with  relativedelta(years=-1)\n",
      "updating global start date\n",
      "Warning: Updated global start date as start date later than global start date.\n"
     ]
    }
   ],
   "source": [
    "from util.config_pat2vec import config_class\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from util.post_processing import process_csv_files\n",
    "from util.post_processing import extract_datetime_to_column\n",
    "from pat2vec_pat_list.get_patient_treatment_list import get_all_patients_list\n",
    "from util.post_processing import produce_filtered_annotation_dataframe\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration dictionary for main options in a medical application\n",
    "main_options_dict = {\n",
    "    # Enable demographic information (Ethnicity mapped to UK census, age, death)\n",
    "    'demo': True,\n",
    "    'bmi': True,  # Enable BMI (Body Mass Index) tracking\n",
    "    'bloods': True,  # Enable blood-related information\n",
    "    'drugs': False,  # Enable drug-related information\n",
    "    'diagnostics': False,  # Enable diagnostic information\n",
    "\n",
    "    'core_02': False,  # Enable core_02 information\n",
    "    'bed': False,  # Enable bed n information\n",
    "    'vte_status': False,  # Enable VTE () status tracking\n",
    "    'hosp_site': False,  # Enable hospital site information\n",
    "    'core_resus': False,  # Enable core resuscitation information\n",
    "    'news': False,  # Enable NEWS (National Early Warning Score) tracking\n",
    "\n",
    "    'smoking': False,  # Enable smoking-related information\n",
    "    'annotations': True,  # Enable EPR annotations\n",
    "    # Enable MRC (Additional clinical note observations index) annotations\n",
    "    'annotations_mrc': True,\n",
    "    # Enable or disable negated presence annotations\n",
    "    'negated_presence_annotations': False\n",
    "}\n",
    "\n",
    "\n",
    "annot_filter_arguments = {\n",
    "    'acc': 0.8,  # base concept accuracy\n",
    "    # umls list of types for medcat filter\n",
    "    'types': ['qualifier value', 'procedure', 'substance', 'finding', 'environment', 'disorder', 'observable entity'],\n",
    "    # 'types': ['qualifier value', 'procedure', 'substance', 'finding', 'environment', 'disorder', 'observable entity', 'organism', 'phenomenon', 'anatomy', 'conceptual entity', 'physical object', 'intellectual product', 'occupation or discipline', 'mental or behavioral dysfunction', 'geographic area', 'population group', 'biomedical or dental material', 'medical device', 'classification', 'regulation or law', 'health care activity', 'health care related organization', 'professional or occupational group', 'group', 'attribute', 'individual behavior']\n",
    "    # Specify the values you want to include in a list. Must be defined in medcat model.\n",
    "    'Time_Value': ['Recent', 'Past'],\n",
    "    'Time_Confidence': 0.8,  # Specify the confidence threshold as a float\n",
    "    # Specify the values you want to include in a list\n",
    "    'Presence_Value': ['True'],\n",
    "    'Presence_Confidence': 0.8,  # Specify the confidence threshold as a float\n",
    "    # Specify the values you want to include in a list\n",
    "    'Subject_Value': ['Patient'],\n",
    "    'Subject_Confidence': 0.8  # Specify the confidence threshold as a float\n",
    "}\n",
    "\n",
    "# Init config obj\n",
    "\n",
    "# Creating a configuration object for a specific task or project\n",
    "config_obj = config_class(\n",
    "    remote_dump=False,  # Flag for remote data dumping. partially deprecated.\n",
    "    suffix='',  # Suffix for file names\n",
    "    # Filename for treatment documentation\n",
    "    treatment_doc_filename='test_files/treatment_docs.csv',\n",
    "    treatment_control_ratio_n=1,  # Ratio for treatment to control\n",
    "    # Project name. patient data batches and vectors stored here.\n",
    "    proj_name='new_project',\n",
    "    current_path_dir=\"\",  # Current path directory\n",
    "    main_options=main_options_dict,  # Dictionary for main options\n",
    "    start_date=(datetime(2020, 1, 1)),  # Starting date for processing\n",
    "    # Number of years to add to the start date. Set the duration of the time window. Window is defined as the start date + years/months/days set here.\n",
    "    years=0,\n",
    "    months=0,  # Number of months to add to the start date\n",
    "    days=2,  # Number of days to add to the start date\n",
    "    # Flag for DGX, set true if in env, each env needs specific paths configured.\n",
    "    dgx=False,\n",
    "    dhcap=False,  # Flag for DHCap\n",
    "    dhcap02=True,  # Flag for DHCap02\n",
    "    batch_mode=True,  # Flag for batch processing mode. only functioning mode.\n",
    "    store_annot=True,  # Flag to store annotations. partially deprecated.\n",
    "    share_sftp=True,  # Flag for sharing via SFTP. partially deprecated\n",
    "    multi_process=False,  # Flag for multi-process execution. deprecated.\n",
    "    annot_first=False,  # Flag for annotation priority. deprecated.\n",
    "    # Flag for stripping lists, will check for completed patients before starting to avoid redundancy.\n",
    "    strip_list=True,\n",
    "    verbosity=0,  # Verbosity level 0-9 printing debug messages\n",
    "    random_seed_val=42,  # Random seed value for reproducibility of controls.\n",
    "    testing=True,  # Flag for testing mode\n",
    "    # Flag for using controls. #will add desired ratio of controls at random from global pool.\n",
    "    use_controls=False,\n",
    "    # Flag for MedCAT processing. #will load medcat into memory and use for annotating.\n",
    "    medcat=True,\n",
    "    # Current timestamp as the start time for logging and progress bar\n",
    "    start_time=datetime.now(),\n",
    "    # Column name for patient ID, auto will try to find it. Example \"client_idcode\"\n",
    "    patient_id_column_name='auto',\n",
    "    annot_filter_options=annot_filter_arguments,  # Annotation filtering options\n",
    "    # Global start year. #set the limits of the time window data can be drawn from. Start should not precede start date set above.\n",
    "    global_start_year=1995, # Global dates are overwritten by individual patient windows to match patient window.\n",
    "    global_start_month=1,  # Global start month\n",
    "    global_end_year=2023,  # Global end year\n",
    "    global_end_month=1, # Global end month\n",
    "    global_start_day = 1, \n",
    "    global_end_day = 1, \n",
    "    shuffle_pat_list=False,  # Flag for shuffling patient list\n",
    "    time_window_interval_delta = relativedelta(years=1), #specify the time window to collapse each feature vector into, years=1 is one vector per year within the global time window\n",
    "    split_clinical_notes=True, #will split clinical notes by date and treat as individual documents with extracted dates. Requires note splitter module. \n",
    "    lookback = True, # when calculating individual patient window from table of start dates, will calculate backwards in time if true. Else Forwards. \n",
    "    add_icd10 = False, #append icd 10 codes to annot batches\n",
    "    add_opc4s=False, # needs icd10 true also.\n",
    "    override_medcat_model_path = None, #Force medcat model path, if None uses defaults for env.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cogstack/samora/_data/gloabl_files/pat2vec/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "refreshed\n",
      "refreshed\n",
      "******Watcher connected to ES Cluster!******\n",
      "\n",
      "Cogstack toolbox functions:\n",
      "cohort_searcher_with_terms_and_search(index_name, fields_list, term_name, entered_list, search_string) = Search with terms and search string\n",
      "cohort_searcher_with_terms_no_search(index_name, fields_list, term_name, entered_list) = Search with terms only\n",
      "cohort_searcher_no_terms(index_name, fields_list, search_string) = Search with search string only\n",
      "matcher(data_template_df, lab_results_df, source_patid_colname, source_date_colname, result_date_colname, result_testname, result_resultname, before, after) = match template with dataset\n",
      "**NOTE: matcher throws up an error if dates are not converted to datetime**\n",
      "stringlist2searchlist(string_list, output_name) = convert a list of strings to a lucene search string\n",
      "pylist2searchlist(list_name, output_name) = convert a list of strings to a python list\n",
      "stringlist2pylist(string_list, var_name) = convert a python list to a lucene search string\n",
      "date_cleaner(dfs, cols, date_format) = specify the df(s) and columns to convert them to the correct datatype\n",
      "bulk_str_extract(target_colname_regex_pairs, source_colname, df_name) = target_colname_regex_pairs = {\"col_title\":r'regex_string'}\n",
      "bulk_str_findall(target_colname_regex_pairs, source_colname, df_name)\n",
      "demo_columns = \"client_idcode\", \"client_firstname\", \"client_lastname\", \"client_dob\", \"client_gendercode\", \"client_racecode\", \"client_deceaseddtm\", \"updatetime\"\n",
      "\n",
      "******Watcher connected to ES Cluster!******\n"
     ]
    }
   ],
   "source": [
    "from main_pat2vec import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init cohort_searcher_with_terms_and_search_dummy function\n",
      "Initialized pat2vec.main\n",
      "Setting NO gpu, most free memory: 3999 !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bar desc:   0%|\u001b[32m          \u001b[0m| 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable 'medcat_path' imported successfully from 'paths.py' file.\n",
      "medcat_path: /home/cogstack/samora/_data/medcat_models/medcat_model_pack_bec3865f4a29ee20.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 22:08:16.780684: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-06 22:08:16.780739: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-06 22:08:16.782595: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-06 22:08:16.793206: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 22:08:17.935503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "pat2vec_obj = main( cogstack=True, use_filter=False,\n",
    "             json_filter_path = None, random_seed_val=42, \n",
    "             hostname =None, config_obj= config_obj, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View patient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D3232DUM23', 'Z982DUM23', 'P545DUM23']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat2vec_obj.all_patient_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pat vectors for pat 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s: None | D3232DUM23 | task: \u001b[33mannot_pat_batch_docs_get_entities_multi_texts | {'n_docs_to_annotate': 4}:   0%|          | 0/3 [00:49<?, ?it/s]t/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "generate_basic_observations_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s: None | D3232DUM23_(2020, 1, 1) | task: \u001b[33mColumns n=8 | {}:   0%|          | 0/3 [00:50<?, ?it/s]t/s]                                            "
     ]
    }
   ],
   "source": [
    "pat2vec_obj.pat_maker(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specific patient raw documents and annotations:\n",
    "#from pat2vec.util.post_processing import remove_file_from_paths\n",
    "\n",
    "# remove_file_from_paths(pat2vec_obj.all_patient_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s: None | Z982DUM23 | task: \u001b[33mannot_pat_batch_docs_get_entities_multi_texts | {'n_docs_to_annotate': 9}:  33%|███▎      | 1/3 [00:50<01:40, 50.11s/it]/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "generate_basic_observations_data\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "generate_basic_observations_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "s: None | P545DUM23 | task: \u001b[33mannot_pat_batch_docs_get_entities_multi_texts | {'n_docs_to_annotate': 9}:  67%|██████▋   | 2/3 [00:50<00:21, 21.05s/it]/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "2020 1 1 2023 1 1\n",
      "generate_basic_observations_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.79it/s]mColumns n=8 | {}: 100%|██████████| 3/3 [00:51<00:00, 11.86s/it]/it]                                            \n",
      "s: None | P545DUM23_(2020, 1, 1) | task: \u001b[33mColumns n=8 | {}: 100%|██████████| 3/3 [00:51<00:00, 17.25s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in tqdm(range(0,len(pat2vec_obj.all_patient_list))):\n",
    "    \n",
    "    pat2vec_obj.pat_maker(i)\n",
    "    pat2vec_obj.t.update(1)\n",
    "    \n",
    "pat2vec_obj.t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file new_project/outputs/concatenated_data_concatenated_output.csv does not exist or overwrite is set to True\n",
      "all files size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3083.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desried cores: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 455.80it/s]\n",
      "Writing lines...: 100%|██████████| 1/1 [00:00<00:00, 9892.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated data saved to new_project/outputs/concatenated_data_concatenated_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "from util.post_processing import process_csv_files_multi\n",
    "\n",
    "# Set the directory paths and file names\n",
    "input_directory = f'{pat2vec_obj.proj_name}/current_pat_lines_parts'\n",
    "output_csv_file = 'concatenated_output'\n",
    "out_folder = f'{pat2vec_obj.proj_name}/outputs'\n",
    "out_file_path = os.path.join(out_folder, f'concatenated_data_{output_csv_file}.csv')\n",
    "overwrite = True\n",
    "use_polars = False\n",
    "\n",
    "# Check if the output file exists and if overwrite is set to False\n",
    "if os.path.exists(out_file_path) and not overwrite:\n",
    "    print(f'The file {out_file_path} exists and overwrite is set to False')\n",
    "    if use_polars:\n",
    "        dfp = pl.read_csv(out_file_path)\n",
    "        df = dfp.to_pandas()\n",
    "    else:\n",
    "        df = pd.read_csv(out_file_path, engine='pyarrow')\n",
    "else:\n",
    "    print(f'The file {out_file_path} does not exist or overwrite is set to True')\n",
    "    try:\n",
    "        # Call the function to process CSV files\n",
    "        process_csv_files_multi(input_directory, out_folder=out_folder, output_filename_suffix=output_csv_file, part_size=20, sample_size=None, n_proc='half')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    # Read the output file after processing\n",
    "    if use_polars:\n",
    "        dfp = pl.read_csv(out_file_path)\n",
    "        df = dfp.to_pandas()\n",
    "    else:\n",
    "        df = pd.read_csv(out_file_path, engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(out_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_idcode</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>(2020, 1, 1)_date_time_stamp</th>\n",
       "      <th>order_entered</th>\n",
       "      <th>order_name</th>\n",
       "      <th>order_holdreasontext</th>\n",
       "      <th>clientvisit_visitidcode</th>\n",
       "      <th>order_summaryline</th>\n",
       "      <th>order_guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z982DUM23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P545DUM23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  client_idcode  Unnamed: 1  (2020, 1, 1)_date_time_stamp  order_entered  \\\n",
       "0    D3232DUM23           0                           1.0            NaN   \n",
       "1     Z982DUM23           0                           1.0            NaN   \n",
       "2     P545DUM23           0                           1.0            NaN   \n",
       "\n",
       "   order_name  order_holdreasontext  clientvisit_visitidcode  \\\n",
       "0         NaN                   NaN                      NaN   \n",
       "1         NaN                   NaN                      NaN   \n",
       "2         NaN                   NaN                      NaN   \n",
       "\n",
       "   order_summaryline  order_guid  \n",
       "0                NaN         NaN  \n",
       "1                NaN         NaN  \n",
       "2                NaN         NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1353.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted_datetime_stamp\n",
      "2020-01-01    3\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = extract_datetime_to_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the annotation batches by a snomed cui and its related codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40733004\n",
      "40733004\n",
      "Retrieving 40733004 with recursion 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.80s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([20480004, 27648007, 46080009, 42197002, 40149008], 1690, 1395)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snomed_methods import snomed_methods_v1\n",
    "snomed_relations_obj = snomed_methods_v1.snomed_relations(medcat=True, snomed_rf2_full_path=None)\n",
    "\n",
    "outcome_variable_cui_for_filter = '40733004'  # infection\n",
    "\n",
    "print(outcome_variable_cui_for_filter)\n",
    "\n",
    "filter_root_cui = outcome_variable_cui_for_filter\n",
    "print(filter_root_cui)\n",
    "\n",
    "retrieved_codes_snomed_tree, retrieved_names_snomed_tree = snomed_relations_obj.recursive_code_expansion(filter_root_cui, n_recursion = 3, debug=False)\n",
    "\n",
    "retrieved_codes_snomed_tree[0:5], len(retrieved_codes_snomed_tree), len(retrieved_names_snomed_tree)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tonsillar actinomycosis (disorder)',\n",
       " 'Abrasion and/or friction burn of ankle with infection (disorder)',\n",
       " 'Disease caused by Gram-negative bacillus (disorder)',\n",
       " 'Rhinosporidial papilloma (disorder)',\n",
       " 'Nonvenomous insect bite of wrist with infection (disorder)',\n",
       " 'Abscess gonococcal (disorder)',\n",
       " 'Hepatitis due to infection (disorder)',\n",
       " 'Malarial pigment deposition (disorder)',\n",
       " 'Emphysematous cystitis (disorder)',\n",
       " 'Methicillin resistant Staphylococcus aureus infection (disorder)']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_names_snomed_tree[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_codes_medcat_cdb, retrieved_names_medcat_cdb  = snomed_relations_obj.get_medcat_cdb_most_similar(filter_root_cui, context_type = 'xxxlong', type_id_filter=[], topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Infectious disease (disorder)',\n",
       " 'Bacterial infectious disease (disorder)',\n",
       " 'Acute infectious disease (disorder)',\n",
       " 'Superimposed infection (disorder)',\n",
       " 'Localized infection (disorder)',\n",
       " 'Viral disease (disorder)',\n",
       " 'Mycoplasma infection (disorder)',\n",
       " 'Source of infection (attribute)',\n",
       " 'Anemia due to infection (disorder)',\n",
       " 'New infection (qualifier value)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_names_medcat_cdb[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1405\n"
     ]
    }
   ],
   "source": [
    "all_names_list = list(set(retrieved_names_medcat_cdb + retrieved_names_snomed_tree))\n",
    "\n",
    "all_codes_list = list(set(retrieved_codes_medcat_cdb + retrieved_codes_snomed_tree))\n",
    "\n",
    "print(len(all_names_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 156.32it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_pat_list_ = get_all_patients_list(config_obj=pat2vec_obj.config_obj)\n",
    "\n",
    "\n",
    "all_annot_filtered_df = produce_filtered_annotation_dataframe(cui_filter=True, meta_annot_filter=True, pat_list=all_pat_list_, config_obj=pat2vec_obj.config_obj, filter_custom_args=pat2vec_obj.config_obj.annot_filter_options, cui_code_list=all_codes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>client_idcode</th>\n",
       "      <th>updatetime</th>\n",
       "      <th>pretty_name</th>\n",
       "      <th>cui</th>\n",
       "      <th>type_ids</th>\n",
       "      <th>types</th>\n",
       "      <th>source_value</th>\n",
       "      <th>detected_name</th>\n",
       "      <th>acc</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>Time_Value</th>\n",
       "      <th>Time_Confidence</th>\n",
       "      <th>Presence_Value</th>\n",
       "      <th>Presence_Confidence</th>\n",
       "      <th>Subject_Value</th>\n",
       "      <th>Subject_Confidence</th>\n",
       "      <th>text_sample</th>\n",
       "      <th>full_doc</th>\n",
       "      <th>document_guid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, client_idcode, updatetime, pretty_name, cui, type_ids, types, source_value, detected_name, acc, context_similarity, start, end, icd10, ontologies, snomed, id, Time_Value, Time_Confidence, Presence_Value, Presence_Confidence, Subject_Value, Subject_Confidence, text_sample, full_doc, document_guid]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_annot_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 1 1 2023 1 1\n",
      "Error retrieving batch EPR documents: Cannot save file into a non-existent directory: '/home/cogstack/samora/_data/gloabl_files/pat2vec/notebooks/new_project/current_pat_document_batches'\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "Error retrieving batch EPR documents.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/samora/_data/gloabl_files/pat2vec/patvec_get_batch_methods/main.py:451\u001b[0m, in \u001b[0;36mget_pat_batch_epr_docs\u001b[0;34m(current_pat_client_id_code, search_term, config_obj, cohort_searcher_with_terms_and_search)\u001b[0m\n\u001b[1;32m    448\u001b[0m             batch_target \u001b[38;5;241m=\u001b[39m split_and_append_chunks(batch_target, epr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 451\u001b[0m         \u001b[43mbatch_target\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_epr_target_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/samora/pat2vec_env/lib/python3.9/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/samora/pat2vec_env/lib/python3.9/site-packages/pandas/core/generic.py:3961\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3952\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3953\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3954\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3958\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3959\u001b[0m )\n\u001b[0;32m-> 3961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3964\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/samora/pat2vec_env/lib/python3.9/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n",
      "File \u001b[0;32m~/samora/pat2vec_env/lib/python3.9/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n",
      "File \u001b[0;32m~/samora/pat2vec_env/lib/python3.9/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n",
      "File \u001b[0;32m~/samora/pat2vec_env/lib/python3.9/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/home/cogstack/samora/_data/gloabl_files/pat2vec/notebooks/new_project/current_pat_document_batches'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m config_obj \u001b[38;5;241m=\u001b[39m config_obj\n\u001b[1;32m      8\u001b[0m cohort_searcher_with_terms_and_search \u001b[38;5;241m=\u001b[39m pat2vec_obj\u001b[38;5;241m.\u001b[39mcohort_searcher_with_terms_and_search\n\u001b[0;32m---> 10\u001b[0m \u001b[43mget_pat_batch_epr_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_pat_client_id_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearch_term\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcohort_searcher_with_terms_and_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcohort_searcher_with_terms_and_search\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/samora/_data/gloabl_files/pat2vec/patvec_get_batch_methods/main.py:461\u001b[0m, in \u001b[0;36mget_pat_batch_epr_docs\u001b[0;34m(current_pat_client_id_code, search_term, config_obj, cohort_searcher_with_terms_and_search)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError retrieving batch EPR documents: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mUnboundLocalError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError retrieving batch EPR documents.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: Error retrieving batch EPR documents."
     ]
    }
   ],
   "source": [
    "from patvec_get_batch_methods.main import get_pat_batch_epr_docs\n",
    "\n",
    "\n",
    "current_pat_client_id_code = ''\n",
    "\n",
    "config_obj = config_obj\n",
    "\n",
    "cohort_searcher_with_terms_and_search = pat2vec_obj.cohort_searcher_with_terms_and_search\n",
    "\n",
    "get_pat_batch_epr_docs(current_pat_client_id_code, 'search_term', config_obj=config_obj, cohort_searcher_with_terms_and_search=cohort_searcher_with_terms_and_search)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = generate_epr_documents_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
