{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def cohort_searcher_with_terms_and_search_dummy(index_name, fields_list, term_name, entered_list, search_string):\n",
    "    # Create an empty dataframe with the specified columns\n",
    "    synthetic_data = pd.DataFrame(columns=fields_list)\n",
    "    \n",
    "    # Assuming 'time' column is part of fields_list, get the index of the time column\n",
    "    time_column_index = fields_list.index('updatetime')\n",
    "    \n",
    "    # Iterate through entered_list to generate synthetic data for each patient\n",
    "    for patient_id in entered_list:\n",
    "        # Generate random data based on conditions (adjust this part based on your specific requirements)\n",
    "        num_rows_per_patient = np.random.randint(5, 20)  # Adjust the range as needed\n",
    "        patient_data = {\n",
    "            'client_idcode': [patient_id] * num_rows_per_patient,\n",
    "            'updatetime': [generate_random_datetime() for _ in range(num_rows_per_patient)],\n",
    "            # Add other columns and their synthetic data generation here\n",
    "        }\n",
    "        \n",
    "        # Convert the dictionary to a temporary dataframe\n",
    "        patient_df = pd.DataFrame(patient_data)\n",
    "        \n",
    "        # Append the patient's data to the main dataframe\n",
    "        synthetic_data = synthetic_data.append(patient_df, ignore_index=True)\n",
    "    \n",
    "    # Apply the time constraint specified by the search_string\n",
    "    if search_string:\n",
    "        start_time, end_time = extract_time_constraint(search_string)\n",
    "        synthetic_data = synthetic_data[(synthetic_data['updatetime'] >= start_time) & (synthetic_data['updatetime'] <= end_time)]\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "def generate_random_datetime():\n",
    "    # Generate a random datetime within a reasonable range (adjust as needed)\n",
    "    start_date = datetime(2020, 1, 1)\n",
    "    end_date = datetime(2022, 12, 31)\n",
    "    random_time = start_date + timedelta(days=np.random.randint((end_date - start_date).days))\n",
    "    return random_time\n",
    "\n",
    "def extract_time_constraint(search_string):\n",
    "    # Implement logic to extract start and end times from the search string\n",
    "    # For example, if search_string is in the format \"2023-01-01 to 2023-12-31\", extract start and end times\n",
    "    # You may need to adjust this based on your specific date format\n",
    "    start_time_str, end_time_str = search_string.split(' to ')\n",
    "    start_time = pd.to_datetime(start_time_str)\n",
    "    end_time = pd.to_datetime(end_time_str)\n",
    "    return start_time, end_time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_start_year = 2020\n",
    "global_start_month = 1\n",
    "global_end_year = 2022\n",
    "global_end_month = 12\n",
    "\n",
    "current_pat_client_id_code = 'P43DUM2D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'order_typecode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\admin\\Documents\\projects\\pat2vec_time\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'order_typecode'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\Documents\\projects\\pat2vec_time\\util\\cohort_searcher_dummy.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m start_date \u001b[39m=\u001b[39m datetime(global_start_year, global_start_month, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m end_date \u001b[39m=\u001b[39m datetime(global_end_year, global_end_month, \u001b[39m31\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m result_df \u001b[39m=\u001b[39m cohort_searcher_with_terms_and_search_dummy(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     index_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39morder\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     fields_list\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39mclient_idcode order_guid order_name order_summaryline order_holdreasontext order_entered clientvisit_visitidcode\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39m.\u001b[39;49msplit(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     term_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mclient_idcode\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     entered_list\u001b[39m=\u001b[39;49m[current_pat_client_id_code],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     search_string\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39morder_typecode:\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmedication\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m AND \u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m                   \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mupdatetime:[\u001b[39;49m\u001b[39m{\u001b[39;49;00mglobal_start_year\u001b[39m}\u001b[39;49;00m\u001b[39m-\u001b[39;49m\u001b[39m{\u001b[39;49;00mglobal_start_month\u001b[39m}\u001b[39;49;00m\u001b[39m TO \u001b[39;49m\u001b[39m{\u001b[39;49;00mglobal_end_year\u001b[39m}\u001b[39;49;00m\u001b[39m-\u001b[39;49m\u001b[39m{\u001b[39;49;00mglobal_end_month\u001b[39m}\u001b[39;49;00m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     start_date\u001b[39m=\u001b[39;49mstart_date,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     end_date\u001b[39m=\u001b[39;49mend_date\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(result_df)\n",
      "\u001b[1;32mc:\\Users\\admin\\Documents\\projects\\pat2vec_time\\util\\cohort_searcher_dummy.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Filter DataFrame based on the given parameters\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m df \u001b[39m=\u001b[39m df[df[term_name]\u001b[39m.\u001b[39misin(entered_list) \u001b[39m&\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39morder_typecode\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39meq(\u001b[39m'\u001b[39m\u001b[39mmedication\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Generate random 'updatetime' values between start_date and end_date\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X25sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mupdatetime\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [generate_random_date(start_date, end_date) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(df))]\n",
      "File \u001b[1;32mc:\\Users\\admin\\Documents\\projects\\pat2vec_time\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\admin\\Documents\\projects\\pat2vec_time\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'order_typecode'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "def generate_random_date(start_date, end_date):\n",
    "    # Generate a random date between start_date and end_date\n",
    "    return start_date + timedelta(\n",
    "        days=random.randint(0, (end_date - start_date).days),\n",
    "        hours=random.randint(0, 23),\n",
    "        minutes=random.randint(0, 59),\n",
    "        seconds=random.randint(0, 59)\n",
    "    )\n",
    "\n",
    "def cohort_searcher_with_terms_and_search_dummy(index_name, fields_list, term_name, entered_list, search_string, start_date, end_date):\n",
    "    # Dummy data for demonstration\n",
    "    data = {\n",
    "        'client_idcode': [1, 2, 3],\n",
    "        'order_guid': ['guid1', 'guid2', 'guid3'],\n",
    "        'order_name': ['name1', 'name2', 'name3'],\n",
    "        'order_summaryline': ['summary1', 'summary2', 'summary3'],\n",
    "        'order_holdreasontext': ['reason1', 'reason2', 'reason3'],\n",
    "        'order_entered': ['entered1', 'entered2', 'entered3'],\n",
    "        'clientvisit_visitidcode': ['visit1', 'visit2', 'visit3']\n",
    "    }\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Filter DataFrame based on the given parameters\n",
    "    df = df[df[term_name].isin(entered_list) & df['order_typecode'].eq('medication')]\n",
    "\n",
    "    # Generate random 'updatetime' values between start_date and end_date\n",
    "    df['updatetime'] = [generate_random_date(start_date, end_date) for _ in range(len(df))]\n",
    "\n",
    "    return df[fields_list + ['updatetime']]\n",
    "\n",
    "# Example usage\n",
    "current_pat_client_id_code = 'your_client_id_code'\n",
    "global_start_year = 2023\n",
    "global_start_month = 1\n",
    "global_end_year = 2023\n",
    "global_end_month = 12\n",
    "\n",
    "start_date = datetime(global_start_year, global_start_month, 1)\n",
    "end_date = datetime(global_end_year, global_end_month, 31)\n",
    "\n",
    "result_df = cohort_searcher_with_terms_and_search_dummy(\n",
    "    index_name=\"order\",\n",
    "    fields_list=\"\"\"client_idcode order_guid order_name order_summaryline order_holdreasontext order_entered clientvisit_visitidcode\"\"\".split(),\n",
    "    term_name=\"client_idcode\",\n",
    "    entered_list=[current_pat_client_id_code],\n",
    "    search_string=f'order_typecode:\"medication\" AND '\n",
    "                  f'updatetime:[{global_start_year}-{global_start_month} TO {global_end_year}-{global_end_month}]',\n",
    "    start_date=start_date,\n",
    "    end_date=end_date\n",
    ")\n",
    "\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'updatetime' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\Documents\\projects\\pat2vec_time\\util\\cohort_searcher_dummy.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m batch_target \u001b[39m=\u001b[39m cohort_searcher_with_terms_and_search_dummy(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m             index_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39morder\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m             fields_list\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39mclient_idcode order_guid order_name order_summaryline order_holdreasontext order_entered clientvisit_visitidcode\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39m.\u001b[39;49msplit(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m             term_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mclient_idcode.keyword\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             entered_list\u001b[39m=\u001b[39;49m[current_pat_client_id_code],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             search_string\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39morder_typecode:\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmedication\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m AND \u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                           \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mupdatetime:[\u001b[39;49m\u001b[39m{\u001b[39;49;00mglobal_start_year\u001b[39m}\u001b[39;49;00m\u001b[39m-\u001b[39;49m\u001b[39m{\u001b[39;49;00mglobal_start_month\u001b[39m}\u001b[39;49;00m\u001b[39m TO \u001b[39;49m\u001b[39m{\u001b[39;49;00mglobal_end_year\u001b[39m}\u001b[39;49;00m\u001b[39m-\u001b[39;49m\u001b[39m{\u001b[39;49;00mglobal_end_month\u001b[39m}\u001b[39;49;00m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\admin\\Documents\\projects\\pat2vec_time\\util\\cohort_searcher_dummy.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m synthetic_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns\u001b[39m=\u001b[39mfields_list)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Assuming 'time' column is part of fields_list, get the index of the time column\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m time_column_index \u001b[39m=\u001b[39m fields_list\u001b[39m.\u001b[39;49mindex(\u001b[39m'\u001b[39;49m\u001b[39mupdatetime\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Iterate through entered_list to generate synthetic data for each patient\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m patient_id \u001b[39min\u001b[39;00m entered_list:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Documents/projects/pat2vec_time/util/cohort_searcher_dummy.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# Generate random data based on conditions (adjust this part based on your specific requirements)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'updatetime' is not in list"
     ]
    }
   ],
   "source": [
    "batch_target = cohort_searcher_with_terms_and_search_dummy(\n",
    "            index_name=\"order\",\n",
    "            fields_list=\"\"\"client_idcode order_guid order_name order_summaryline order_holdreasontext order_entered clientvisit_visitidcode\"\"\".split(),\n",
    "            term_name=\"client_idcode.keyword\",\n",
    "            entered_list=[current_pat_client_id_code],\n",
    "            search_string=f'order_typecode:\"medication\" AND '\n",
    "                          f'updatetime:[{global_start_year}-{global_start_month} TO {global_end_year}-{global_end_month}]'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "index_name = 'dummy_index'\n",
    "fields_list = ['patient_id', 'time', 'value1', 'value2']  # Add other columns as needed\n",
    "term_name = 'dummy_term'\n",
    "entered_list = ['patient1', 'patient2', 'patient3']\n",
    "search_string = '2023-01-01 to 2023-12-31'\n",
    "\n",
    "result_df = cohort_searcher_with_terms_and_search_dummy(index_name, fields_list, term_name, entered_list, search_string)\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dataframe_by_timestamp(pat_batch, start_year, start_month, end_year, end_month, start_day, end_day, 'order_entered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_pat_drugs(current_pat_client_id_code, target_date_range, batch_drugs, config_obj=config_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year, start_month, end_year, end_month, start_day, end_day = get_start_end_year_month(target_date_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pat_batch_drugs(current_pat_client_id_code, search_term, config_obj=None, cohort_searcher_with_terms_and_search=None):\n",
    "\n",
    "    if config_obj is None or not all(hasattr(config_obj, attr) for attr in ['global_start_year', 'global_start_month', 'global_end_year', 'global_end_month']):\n",
    "        raise ValueError(\"Invalid or missing configuration object.\")\n",
    "\n",
    "    global_start_year = config_obj.global_start_year\n",
    "    global_start_month = config_obj.global_start_month\n",
    "    global_end_year = config_obj.global_end_year\n",
    "    global_end_month = config_obj.global_end_month\n",
    "\n",
    "    try:\n",
    "        batch_target = cohort_searcher_with_terms_and_search(\n",
    "            index_name=\"order\",\n",
    "            fields_list=\"\"\"client_idcode order_guid order_name order_summaryline order_holdreasontext order_entered clientvisit_visitidcode\"\"\".split(),\n",
    "            term_name=\"client_idcode.keyword\",\n",
    "            entered_list=[current_pat_client_id_code],\n",
    "            search_string=f'order_typecode:\"medication\" AND '\n",
    "                          f'updatetime:[{global_start_year}-{global_start_month} TO {global_end_year}-{global_end_month}]'\n",
    "        )\n",
    "        return batch_target\n",
    "    except Exception as e:\n",
    "        \"\"\n",
    "        print(f\"Error retrieving batch medication orders: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " batch_target = cohort_searcher_with_terms_and_search_dummy(\n",
    "                index_name=\"epr_documents\",\n",
    "                fields_list=\"\"\"client_idcode document_guid document_description body_analysed updatetime clientvisit_visitidcode\"\"\".split(),\n",
    "                term_name=\"client_idcode.keyword\",\n",
    "                entered_list=[current_pat_client_id_code],\n",
    "                search_string=f'updatetime:[{global_start_year}-{global_start_month} TO {global_end_year}-{global_end_month}]'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_idcode</th>\n",
       "      <th>document_guid</th>\n",
       "      <th>document_description</th>\n",
       "      <th>body_analysed</th>\n",
       "      <th>updatetime</th>\n",
       "      <th>clientvisit_visitidcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_0</td>\n",
       "      <td>description_0</td>\n",
       "      <td>body_0</td>\n",
       "      <td>2023-01-19 18:03:50</td>\n",
       "      <td>visit_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_1</td>\n",
       "      <td>description_1</td>\n",
       "      <td>body_1</td>\n",
       "      <td>2022-06-11 08:00:50</td>\n",
       "      <td>visit_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_2</td>\n",
       "      <td>description_2</td>\n",
       "      <td>body_2</td>\n",
       "      <td>2022-05-27 16:38:16</td>\n",
       "      <td>visit_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_3</td>\n",
       "      <td>description_3</td>\n",
       "      <td>body_3</td>\n",
       "      <td>2022-10-03 07:30:40</td>\n",
       "      <td>visit_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_4</td>\n",
       "      <td>description_4</td>\n",
       "      <td>body_4</td>\n",
       "      <td>2022-08-23 00:09:21</td>\n",
       "      <td>visit_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_5</td>\n",
       "      <td>description_5</td>\n",
       "      <td>body_5</td>\n",
       "      <td>2023-11-06 14:44:13</td>\n",
       "      <td>visit_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_6</td>\n",
       "      <td>description_6</td>\n",
       "      <td>body_6</td>\n",
       "      <td>2022-12-11 13:38:13</td>\n",
       "      <td>visit_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_7</td>\n",
       "      <td>description_7</td>\n",
       "      <td>body_7</td>\n",
       "      <td>2022-02-01 06:45:38</td>\n",
       "      <td>visit_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_8</td>\n",
       "      <td>description_8</td>\n",
       "      <td>body_8</td>\n",
       "      <td>2023-08-14 05:52:22</td>\n",
       "      <td>visit_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_9</td>\n",
       "      <td>description_9</td>\n",
       "      <td>body_9</td>\n",
       "      <td>2023-05-28 08:18:17</td>\n",
       "      <td>visit_9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  client_idcode document_guid document_description body_analysed  \\\n",
       "0    D3232DUM23         doc_0        description_0        body_0   \n",
       "1    D3232DUM23         doc_1        description_1        body_1   \n",
       "2    D3232DUM23         doc_2        description_2        body_2   \n",
       "3    D3232DUM23         doc_3        description_3        body_3   \n",
       "4    D3232DUM23         doc_4        description_4        body_4   \n",
       "5    D3232DUM23         doc_5        description_5        body_5   \n",
       "6    D3232DUM23         doc_6        description_6        body_6   \n",
       "7    D3232DUM23         doc_7        description_7        body_7   \n",
       "8    D3232DUM23         doc_8        description_8        body_8   \n",
       "9    D3232DUM23         doc_9        description_9        body_9   \n",
       "\n",
       "           updatetime clientvisit_visitidcode  \n",
       "0 2023-01-19 18:03:50                 visit_0  \n",
       "1 2022-06-11 08:00:50                 visit_1  \n",
       "2 2022-05-27 16:38:16                 visit_2  \n",
       "3 2022-10-03 07:30:40                 visit_3  \n",
       "4 2022-08-23 00:09:21                 visit_4  \n",
       "5 2023-11-06 14:44:13                 visit_5  \n",
       "6 2022-12-11 13:38:13                 visit_6  \n",
       "7 2022-02-01 06:45:38                 visit_7  \n",
       "8 2023-08-14 05:52:22                 visit_8  \n",
       "9 2023-05-28 08:18:17                 visit_9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_dummy_data(index_name, fields_list, term_name, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    # Check if index_name is 'epr_documents'\n",
    "    if index_name == \"epr_documents\":\n",
    "        # Dummy data for current_pat_client_id_code\n",
    "        current_pat_client_id_code = random.choice(entered_list)\n",
    "\n",
    "        # Generate random data for the specified columns\n",
    "        num_rows = 10  # You can adjust the number of rows as needed\n",
    "        data = {\n",
    "            'client_idcode': [random.choice(entered_list) for _ in range(num_rows)],\n",
    "            'document_guid': [f'doc_{i}' for i in range(num_rows)],\n",
    "            'document_description': [f'description_{i}' for i in range(num_rows)],\n",
    "            'body_analysed': [f'body_{i}' for i in range(num_rows)],\n",
    "            'updatetime': [datetime(\n",
    "                random.randint(global_start_year, global_end_year),\n",
    "                random.randint(1, 12),\n",
    "                random.randint(1, 28),\n",
    "                random.randint(0, 23),\n",
    "                random.randint(0, 59),\n",
    "                random.randint(0, 59)\n",
    "            ) for _ in range(num_rows)],\n",
    "            'clientvisit_visitidcode': [f'visit_{i}' for i in range(num_rows)]\n",
    "        }\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(data, columns=fields_list)\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Index name is not 'epr_documents'. No data generated.\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "dummy_df = generate_dummy_data(\n",
    "    index_name=\"epr_documents\",\n",
    "    fields_list=\"\"\"client_idcode document_guid document_description body_analysed updatetime clientvisit_visitidcode\"\"\".split(),\n",
    "    term_name=\"client_idcode.keyword\",\n",
    "    entered_list=['D3232DUM23'],  # Add more client IDs as needed\n",
    "    global_start_year=2022,\n",
    "    global_start_month=1,\n",
    "    global_end_year=2023,\n",
    "    global_end_month=12\n",
    ")\n",
    "\n",
    "display(dummy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_idcode</th>\n",
       "      <th>document_guid</th>\n",
       "      <th>document_description</th>\n",
       "      <th>body_analysed</th>\n",
       "      <th>updatetime</th>\n",
       "      <th>clientvisit_visitidcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_0</td>\n",
       "      <td>description_0</td>\n",
       "      <td>Treatment heart carry garden view much accordi...</td>\n",
       "      <td>2022-04-02 05:27:37</td>\n",
       "      <td>visit_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_1</td>\n",
       "      <td>description_1</td>\n",
       "      <td>Watch begin contain project. Parent out eye vi...</td>\n",
       "      <td>2022-02-07 03:49:10</td>\n",
       "      <td>visit_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_2</td>\n",
       "      <td>description_2</td>\n",
       "      <td>Rise our per push. Upon character appear never...</td>\n",
       "      <td>2023-05-19 17:33:30</td>\n",
       "      <td>visit_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_3</td>\n",
       "      <td>description_3</td>\n",
       "      <td>Put billion everything my team treatment image...</td>\n",
       "      <td>2023-01-12 10:22:23</td>\n",
       "      <td>visit_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_4</td>\n",
       "      <td>description_4</td>\n",
       "      <td>Nearly nothing data. Real while kind compare s...</td>\n",
       "      <td>2023-10-03 14:55:13</td>\n",
       "      <td>visit_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_5</td>\n",
       "      <td>description_5</td>\n",
       "      <td>See boy bag. Take hotel take entire charge wis...</td>\n",
       "      <td>2023-10-19 06:29:19</td>\n",
       "      <td>visit_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_6</td>\n",
       "      <td>description_6</td>\n",
       "      <td>Pressure mind blue something. Rule travel spee...</td>\n",
       "      <td>2023-07-18 20:04:31</td>\n",
       "      <td>visit_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_7</td>\n",
       "      <td>description_7</td>\n",
       "      <td>Skill strong eye keep measure cause. Race so m...</td>\n",
       "      <td>2022-11-08 11:57:50</td>\n",
       "      <td>visit_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_8</td>\n",
       "      <td>description_8</td>\n",
       "      <td>Whom crime center sport common piece. Hospital...</td>\n",
       "      <td>2022-01-25 12:17:56</td>\n",
       "      <td>visit_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_9</td>\n",
       "      <td>description_9</td>\n",
       "      <td>Though huge low education war democratic stand...</td>\n",
       "      <td>2023-11-08 22:54:09</td>\n",
       "      <td>visit_9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  client_idcode document_guid document_description  \\\n",
       "0    D3232DUM23         doc_0        description_0   \n",
       "1    D3232DUM23         doc_1        description_1   \n",
       "2    D3232DUM23         doc_2        description_2   \n",
       "3    D3232DUM23         doc_3        description_3   \n",
       "4    D3232DUM23         doc_4        description_4   \n",
       "5    D3232DUM23         doc_5        description_5   \n",
       "6    D3232DUM23         doc_6        description_6   \n",
       "7    D3232DUM23         doc_7        description_7   \n",
       "8    D3232DUM23         doc_8        description_8   \n",
       "9    D3232DUM23         doc_9        description_9   \n",
       "\n",
       "                                       body_analysed          updatetime  \\\n",
       "0  Treatment heart carry garden view much accordi... 2022-04-02 05:27:37   \n",
       "1  Watch begin contain project. Parent out eye vi... 2022-02-07 03:49:10   \n",
       "2  Rise our per push. Upon character appear never... 2023-05-19 17:33:30   \n",
       "3  Put billion everything my team treatment image... 2023-01-12 10:22:23   \n",
       "4  Nearly nothing data. Real while kind compare s... 2023-10-03 14:55:13   \n",
       "5  See boy bag. Take hotel take entire charge wis... 2023-10-19 06:29:19   \n",
       "6  Pressure mind blue something. Rule travel spee... 2023-07-18 20:04:31   \n",
       "7  Skill strong eye keep measure cause. Race so m... 2022-11-08 11:57:50   \n",
       "8  Whom crime center sport common piece. Hospital... 2022-01-25 12:17:56   \n",
       "9  Though huge low education war democratic stand... 2023-11-08 22:54:09   \n",
       "\n",
       "  clientvisit_visitidcode  \n",
       "0                 visit_0  \n",
       "1                 visit_1  \n",
       "2                 visit_2  \n",
       "3                 visit_3  \n",
       "4                 visit_4  \n",
       "5                 visit_5  \n",
       "6                 visit_6  \n",
       "7                 visit_7  \n",
       "8                 visit_8  \n",
       "9                 visit_9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_dummy_data(index_name, fields_list, term_name, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    # Check if index_name is 'epr_documents'\n",
    "    if index_name == \"epr_documents\":\n",
    "        # Dummy data for current_pat_client_id_code\n",
    "        current_pat_client_id_code = random.choice(entered_list)\n",
    "\n",
    "        # Generate random data for the specified columns\n",
    "        num_rows = 10  # You can adjust the number of rows as needed\n",
    "        data = {\n",
    "            'client_idcode': [random.choice(entered_list) for _ in range(num_rows)],\n",
    "            'document_guid': [f'doc_{i}' for i in range(num_rows)],\n",
    "            'document_description': [f'description_{i}' for i in range(num_rows)],\n",
    "            'body_analysed': [fake.paragraph() for _ in range(num_rows)],  # Use Faker for medical text\n",
    "            'updatetime': [datetime(\n",
    "                random.randint(global_start_year, global_end_year),\n",
    "                random.randint(1, 12),\n",
    "                random.randint(1, 28),\n",
    "                random.randint(0, 23),\n",
    "                random.randint(0, 59),\n",
    "                random.randint(0, 59)\n",
    "            ) for _ in range(num_rows)],\n",
    "            'clientvisit_visitidcode': [f'visit_{i}' for i in range(num_rows)]\n",
    "        }\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(data, columns=fields_list)\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Index name is not 'epr_documents'. No data generated.\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "dummy_df = generate_dummy_data(\n",
    "    index_name=\"epr_documents\",\n",
    "    fields_list=\"\"\"client_idcode document_guid document_description body_analysed updatetime clientvisit_visitidcode\"\"\".split(),\n",
    "    term_name=\"client_idcode.keyword\",\n",
    "    entered_list=['D3232DUM23'],  # Add more client IDs as needed\n",
    "    global_start_year=2022,\n",
    "    global_start_month=1,\n",
    "    global_end_year=2023,\n",
    "    global_end_month=12\n",
    ")\n",
    "\n",
    "display(dummy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_idcode</th>\n",
       "      <th>document_guid</th>\n",
       "      <th>document_description</th>\n",
       "      <th>body_analysed</th>\n",
       "      <th>updatetime</th>\n",
       "      <th>clientvisit_visitidcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_0</td>\n",
       "      <td>description_0</td>\n",
       "      <td>Picture fast successful school. Teacher begin ...</td>\n",
       "      <td>2022-03-20 09:22:05</td>\n",
       "      <td>visit_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_1</td>\n",
       "      <td>description_1</td>\n",
       "      <td>New fast fish join. Decide although claim sist...</td>\n",
       "      <td>2022-08-06 05:11:17</td>\n",
       "      <td>visit_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_2</td>\n",
       "      <td>description_2</td>\n",
       "      <td>Us hospital about meeting. Car agent father li...</td>\n",
       "      <td>2023-07-27 00:47:11</td>\n",
       "      <td>visit_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_3</td>\n",
       "      <td>description_3</td>\n",
       "      <td>Now address example mention relationship or bu...</td>\n",
       "      <td>2023-12-08 09:11:47</td>\n",
       "      <td>visit_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_4</td>\n",
       "      <td>description_4</td>\n",
       "      <td>Only less shoulder because seven development. ...</td>\n",
       "      <td>2023-03-24 11:09:03</td>\n",
       "      <td>visit_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_5</td>\n",
       "      <td>description_5</td>\n",
       "      <td>Yes according not community. Citizen expect de...</td>\n",
       "      <td>2023-09-17 23:19:07</td>\n",
       "      <td>visit_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_6</td>\n",
       "      <td>description_6</td>\n",
       "      <td>Green own common sit. International religious ...</td>\n",
       "      <td>2022-03-22 08:16:59</td>\n",
       "      <td>visit_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_7</td>\n",
       "      <td>description_7</td>\n",
       "      <td>Recent speak top person camera in number. Tele...</td>\n",
       "      <td>2022-07-25 22:10:13</td>\n",
       "      <td>visit_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_8</td>\n",
       "      <td>description_8</td>\n",
       "      <td>Mr maybe certain cold. One keep woman act thou...</td>\n",
       "      <td>2022-07-27 11:07:03</td>\n",
       "      <td>visit_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_9</td>\n",
       "      <td>description_9</td>\n",
       "      <td>Save expert every action main number degree ye...</td>\n",
       "      <td>2022-09-18 07:53:32</td>\n",
       "      <td>visit_9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  client_idcode document_guid document_description  \\\n",
       "0    D3232DUM23         doc_0        description_0   \n",
       "1    D3232DUM23         doc_1        description_1   \n",
       "2    D3232DUM23         doc_2        description_2   \n",
       "3    D3232DUM23         doc_3        description_3   \n",
       "4    D3232DUM23         doc_4        description_4   \n",
       "5    D3232DUM23         doc_5        description_5   \n",
       "6    D3232DUM23         doc_6        description_6   \n",
       "7    D3232DUM23         doc_7        description_7   \n",
       "8    D3232DUM23         doc_8        description_8   \n",
       "9    D3232DUM23         doc_9        description_9   \n",
       "\n",
       "                                       body_analysed          updatetime  \\\n",
       "0  Picture fast successful school. Teacher begin ... 2022-03-20 09:22:05   \n",
       "1  New fast fish join. Decide although claim sist... 2022-08-06 05:11:17   \n",
       "2  Us hospital about meeting. Car agent father li... 2023-07-27 00:47:11   \n",
       "3  Now address example mention relationship or bu... 2023-12-08 09:11:47   \n",
       "4  Only less shoulder because seven development. ... 2023-03-24 11:09:03   \n",
       "5  Yes according not community. Citizen expect de... 2023-09-17 23:19:07   \n",
       "6  Green own common sit. International religious ... 2022-03-22 08:16:59   \n",
       "7  Recent speak top person camera in number. Tele... 2022-07-25 22:10:13   \n",
       "8  Mr maybe certain cold. One keep woman act thou... 2022-07-27 11:07:03   \n",
       "9  Save expert every action main number degree ye... 2022-09-18 07:53:32   \n",
       "\n",
       "  clientvisit_visitidcode  \n",
       "0                 visit_0  \n",
       "1                 visit_1  \n",
       "2                 visit_2  \n",
       "3                 visit_3  \n",
       "4                 visit_4  \n",
       "5                 visit_5  \n",
       "6                 visit_6  \n",
       "7                 visit_7  \n",
       "8                 visit_8  \n",
       "9                 visit_9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_epr_documents_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    current_pat_client_id_code = random.choice(entered_list)\n",
    "    \n",
    "    data = {\n",
    "        'client_idcode': [random.choice(entered_list) for _ in range(num_rows)],\n",
    "        'document_guid': [f'doc_{i}' for i in range(num_rows)],\n",
    "        'document_description': [f'description_{i}' for i in range(num_rows)],\n",
    "        'body_analysed': [fake.paragraph() for _ in range(num_rows)],\n",
    "        'updatetime': [datetime(\n",
    "            random.randint(global_start_year, global_end_year),\n",
    "            random.randint(global_start_month, global_end_month),\n",
    "            random.randint(1, 28),\n",
    "            random.randint(0, 23),\n",
    "            random.randint(0, 59),\n",
    "            random.randint(0, 59)\n",
    "        ) for _ in range(num_rows)],\n",
    "        'clientvisit_visitidcode': [f'visit_{i}' for i in range(num_rows)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def cohort_searcher_with_terms_and_search_dummy(index_name, fields_list, term_name, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    if index_name == \"epr_documents\":\n",
    "        num_rows = random.randint(0,10)  # You can adjust the number of rows as needed\n",
    "        df = generate_epr_documents_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Index name is not 'epr_documents'. No data generated.\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "dummy_df = generate_dummy_data(\n",
    "    index_name=\"epr_documents\",\n",
    "    fields_list=\"\"\"client_idcode document_guid document_description body_analysed updatetime clientvisit_visitidcode\"\"\".split(),\n",
    "    term_name=\"client_idcode.keyword\",\n",
    "    entered_list=['D3232DUM23'],  # Add more client IDs as needed\n",
    "    global_start_year=2022,\n",
    "    global_start_month=1,\n",
    "    global_end_year=2023,\n",
    "    global_end_month=12\n",
    ")\n",
    "\n",
    "display(dummy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.1.3-cp310-cp310-win_amd64.whl.metadata (18 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from pandas)\n",
      "  Downloading numpy-1.26.2-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     --------------------------------- ------ 51.2/61.2 kB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 61.2/61.2 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\documents\\projects\\pat2vec_time\\.venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ---------------------------------------- 0.0/341.8 kB ? eta -:--:--\n",
      "     --- ----------------------------------- 30.7/341.8 kB 1.3 MB/s eta 0:00:01\n",
      "     ------------ ------------------------- 112.6/341.8 kB 1.1 MB/s eta 0:00:01\n",
      "     ------------------- ------------------ 174.1/341.8 kB 1.2 MB/s eta 0:00:01\n",
      "     --------------------------- ---------- 245.8/341.8 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------  337.9/341.8 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 341.8/341.8 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\documents\\projects\\pat2vec_time\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.1.3-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "   ---------------------------------------- 0.0/10.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/10.7 MB 5.1 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.3/10.7 MB 2.8 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.4/10.7 MB 3.2 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.4/10.7 MB 3.2 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.5/10.7 MB 2.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/10.7 MB 2.3 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.8/10.7 MB 2.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/10.7 MB 2.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.1/10.7 MB 2.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.2/10.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.3/10.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.4/10.7 MB 2.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.6/10.7 MB 2.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.7/10.7 MB 2.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.9/10.7 MB 2.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.1/10.7 MB 2.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.1/10.7 MB 2.7 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.3/10.7 MB 2.7 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.4/10.7 MB 2.8 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/10.7 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.8/10.7 MB 2.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/10.7 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.1/10.7 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.3/10.7 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.3/10.7 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.5/10.7 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.6/10.7 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.6/10.7 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.6/10.7 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.8/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.0/10.7 MB 2.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.1/10.7 MB 1.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 4.2/10.7 MB 864.5 kB/s eta 0:00:08\n",
      "   ------------------- -------------------- 5.1/10.7 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.2/10.7 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.3/10.7 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.4/10.7 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.6/10.7 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.6/10.7 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.7/10.7 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.8/10.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 5.9/10.7 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.1/10.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.3/10.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.4/10.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.5/10.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.5/10.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.7/10.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.9/10.7 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 6.9/10.7 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.1/10.7 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.2/10.7 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 7.3/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.0/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.0/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.0/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.0/10.7 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.4/10.7 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.8/10.7 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 8.9/10.7 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.0/10.7 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.1/10.7 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.2/10.7 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.3/10.7 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.5/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.6/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.7/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.7/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.8/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.9/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.1/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.2/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.4/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.5/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/10.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.7/10.7 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.2-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.8 MB 4.3 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.3/15.8 MB 3.5 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/15.8 MB 3.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.6/15.8 MB 3.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.7/15.8 MB 3.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.8/15.8 MB 3.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.8/15.8 MB 3.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.8/15.8 MB 3.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.9/15.8 MB 2.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.0/15.8 MB 2.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.2/15.8 MB 2.3 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.2/15.8 MB 2.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.4/15.8 MB 2.3 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 1.5/15.8 MB 2.3 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.6/15.8 MB 2.3 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.7/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.9/15.8 MB 2.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.0/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 2.2/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 2.3/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.4/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.5/15.8 MB 2.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 2.6/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.8/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.9/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 3.0/15.8 MB 2.3 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 3.2/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.3/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 3.4/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.6/15.8 MB 2.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.7/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 3.8/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.0/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.2/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 4.3/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.4/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.4/15.8 MB 2.5 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.6/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.6/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.8/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.9/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 4.9/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 5.0/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 5.1/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 5.1/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.2/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.4/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 5.5/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.6/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.7/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 5.8/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 5.9/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.0/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.1/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.2/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.2/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 6.3/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.4/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.5/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.7/15.8 MB 2.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 6.9/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 7.1/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 7.2/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 7.3/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 7.5/15.8 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 7.5/15.8 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 7.5/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 7.7/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 7.8/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 7.9/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 8.1/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 8.2/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 8.3/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.3/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.4/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.5/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.6/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.7/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 8.8/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 8.8/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 9.0/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 9.0/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 9.1/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 9.5/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 9.7/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 9.8/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 9.9/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 10.1/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 10.2/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.3/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.3/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.5/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.7/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 10.8/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 10.8/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 10.8/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 11.0/15.8 MB 2.2 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 11.0/15.8 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.1/15.8 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.4/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.6/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.7/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.9/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.0/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.0/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.1/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.3/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.3/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.5/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.7/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.8/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 13.0/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 13.0/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.1/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.3/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.3/15.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.8/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.0/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.2/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.3/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.5/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.5/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.6/15.8 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.8/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.0/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.1/15.8 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.3/15.8 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.3/15.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "   ---------------------------------------- 0.0/502.5 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 81.9/502.5 kB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 276.5/502.5 kB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 327.7/502.5 kB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 440.3/502.5 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 502.5/502.5 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.2 pandas-2.1.3 pytz-2023.3.post1 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_guid</th>\n",
       "      <th>client_idcode</th>\n",
       "      <th>obscatalogmasteritem_displayname</th>\n",
       "      <th>observation_valuetext_analysed</th>\n",
       "      <th>observationdocument_recordeddtm</th>\n",
       "      <th>clientvisit_visitidcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>obs_0</td>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>AoMRC_ClinicalSummary_FT</td>\n",
       "      <td>Deal minute especially design item probably si...</td>\n",
       "      <td>2022-05-04 12:01:37</td>\n",
       "      <td>visit_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>obs_1</td>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>AoMRC_ClinicalSummary_FT</td>\n",
       "      <td>Method pull he. Action really black thought dr...</td>\n",
       "      <td>2022-02-12 22:50:45</td>\n",
       "      <td>visit_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>obs_2</td>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>AoMRC_ClinicalSummary_FT</td>\n",
       "      <td>On significant maintain career. International ...</td>\n",
       "      <td>2022-07-07 17:31:43</td>\n",
       "      <td>visit_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  observation_guid client_idcode obscatalogmasteritem_displayname  \\\n",
       "0            obs_0    D3232DUM23         AoMRC_ClinicalSummary_FT   \n",
       "1            obs_1    D3232DUM23         AoMRC_ClinicalSummary_FT   \n",
       "2            obs_2    D3232DUM23         AoMRC_ClinicalSummary_FT   \n",
       "\n",
       "                      observation_valuetext_analysed  \\\n",
       "0  Deal minute especially design item probably si...   \n",
       "1  Method pull he. Action really black thought dr...   \n",
       "2  On significant maintain career. International ...   \n",
       "\n",
       "  observationdocument_recordeddtm clientvisit_visitidcode  \n",
       "0             2022-05-04 12:01:37                 visit_0  \n",
       "1             2022-02-12 22:50:45                 visit_1  \n",
       "2             2022-07-07 17:31:43                 visit_2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_epr_documents_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    current_pat_client_id_code = random.choice(entered_list)\n",
    "    \n",
    "    data = {\n",
    "        'client_idcode': [random.choice(entered_list) for _ in range(num_rows)],\n",
    "        'document_guid': [f'doc_{i}' for i in range(num_rows)],\n",
    "        'document_description': [f'description_{i}' for i in range(num_rows)],\n",
    "        'body_analysed': [fake.paragraph() for _ in range(num_rows)],\n",
    "        'updatetime': [datetime(\n",
    "            random.randint(global_start_year, global_end_year),\n",
    "            random.randint(global_start_month, global_end_month),\n",
    "            random.randint(1, 28),\n",
    "            random.randint(0, 23),\n",
    "            random.randint(0, 59),\n",
    "            random.randint(0, 59)\n",
    "        ) for _ in range(num_rows)],\n",
    "        'clientvisit_visitidcode': [f'visit_{i}' for i in range(num_rows)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def generate_mct_observations_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    current_pat_client_id_code = random.choice(entered_list)\n",
    "    \n",
    "    data = {\n",
    "        'observation_guid': [f'obs_{i}' for i in range(num_rows)],\n",
    "        'client_idcode': [random.choice(entered_list) for _ in range(num_rows)],\n",
    "        'obscatalogmasteritem_displayname': 'AoMRC_ClinicalSummary_FT',\n",
    "        'observation_valuetext_analysed': [fake.paragraph() for _ in range(num_rows)],\n",
    "        'observationdocument_recordeddtm': [datetime(\n",
    "            random.randint(global_start_year, global_end_year),\n",
    "            random.randint(global_start_month, global_end_month),\n",
    "            random.randint(1, 28),\n",
    "            random.randint(0, 23),\n",
    "            random.randint(0, 59),\n",
    "            random.randint(0, 59)\n",
    "        ) for _ in range(num_rows)],\n",
    "        'clientvisit_visitidcode': [f'visit_{i}' for i in range(num_rows)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def cohort_searcher_with_terms_and_search(index_name, fields_list, term_name, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    if index_name == \"epr_documents\":\n",
    "        num_rows = random.randint(0, 10)  # You can adjust the number of rows as needed\n",
    "        df = generate_epr_documents_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)\n",
    "        return df\n",
    "    elif index_name == \"observations\":\n",
    "        num_rows = random.randint(0, 10)  # You can adjust the number of rows as needed\n",
    "        df = generate_mct_observations_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        print(\"Index name is not 'epr_documents' or 'observations'. No data generated.\")\n",
    "        return None\n",
    "\n",
    "# Example usage for observations:\n",
    "observations_df = cohort_searcher_with_terms_and_search(\n",
    "    index_name=\"observations\",\n",
    "    fields_list=\"\"\"observation_guid client_idcode obscatalogmasteritem_displayname\n",
    "                    observation_valuetext_analysed observationdocument_recordeddtm \n",
    "                    clientvisit_visitidcode\"\"\".split(),\n",
    "    term_name=\"client_idcode.keyword\",\n",
    "    entered_list=['D3232DUM23'],  # Add more client IDs as needed\n",
    "    global_start_year=2022,\n",
    "    global_start_month=1,\n",
    "    global_end_year=2023,\n",
    "    global_end_month=12\n",
    ")\n",
    "\n",
    "display(observations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_idcode</th>\n",
       "      <th>basicobs_itemname_analysed</th>\n",
       "      <th>basicobs_value_numeric</th>\n",
       "      <th>basicobs_entered</th>\n",
       "      <th>clientvisit_serviceguid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>power</td>\n",
       "      <td>27.910084</td>\n",
       "      <td>2023-12-05 17:31:55</td>\n",
       "      <td>service_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>out</td>\n",
       "      <td>56.527913</td>\n",
       "      <td>2022-10-28 17:18:56</td>\n",
       "      <td>service_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>mean glass</td>\n",
       "      <td>2.299164</td>\n",
       "      <td>2022-03-24 12:59:43</td>\n",
       "      <td>service_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>respond fight</td>\n",
       "      <td>16.156025</td>\n",
       "      <td>2022-01-22 20:58:00</td>\n",
       "      <td>service_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  client_idcode basicobs_itemname_analysed  basicobs_value_numeric  \\\n",
       "0    D3232DUM23                      power               27.910084   \n",
       "1    D3232DUM23                        out               56.527913   \n",
       "2    D3232DUM23                 mean glass                2.299164   \n",
       "3    D3232DUM23              respond fight               16.156025   \n",
       "\n",
       "     basicobs_entered clientvisit_serviceguid  \n",
       "0 2023-12-05 17:31:55               service_0  \n",
       "1 2022-10-28 17:18:56               service_1  \n",
       "2 2022-03-24 12:59:43               service_2  \n",
       "3 2022-01-22 20:58:00               service_3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_epr_documents_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    current_pat_client_id_code = random.choice(entered_list)\n",
    "    \n",
    "    data = {\n",
    "        'client_idcode': [random.choice(entered_list) for _ in range(num_rows)],\n",
    "        'document_guid': [f'doc_{i}' for i in range(num_rows)],\n",
    "        'document_description': [f'description_{i}' for i in range(num_rows)],\n",
    "        'body_analysed': [fake.paragraph() for _ in range(num_rows)],\n",
    "        'updatetime': [datetime(\n",
    "            random.randint(global_start_year, global_end_year),\n",
    "            random.randint(global_start_month, global_end_month),\n",
    "            random.randint(1, 28),\n",
    "            random.randint(0, 23),\n",
    "            random.randint(0, 59),\n",
    "            random.randint(0, 59)\n",
    "        ) for _ in range(num_rows)],\n",
    "        'clientvisit_visitidcode': [f'visit_{i}' for i in range(num_rows)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def generate_observations_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    current_pat_client_id_code = random.choice(entered_list)\n",
    "    \n",
    "    data = {\n",
    "        'observation_guid': [f'obs_{i}' for i in range(num_rows)],\n",
    "        'client_idcode': [random.choice(entered_list) for _ in range(num_rows)],\n",
    "        'obscatalogmasteritem_displayname': 'AoMRC_ClinicalSummary_FT',\n",
    "        'observation_valuetext_analysed': [fake.paragraph() for _ in range(num_rows)],\n",
    "        'observationdocument_recordeddtm': [datetime(\n",
    "            random.randint(global_start_year, global_end_year),\n",
    "            random.randint(global_start_month, global_end_month),\n",
    "            random.randint(1, 28),\n",
    "            random.randint(0, 23),\n",
    "            random.randint(0, 59),\n",
    "            random.randint(0, 59)\n",
    "        ) for _ in range(num_rows)],\n",
    "        'clientvisit_visitidcode': [f'visit_{i}' for i in range(num_rows)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def generate_basic_observations_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    current_pat_client_id_code = random.choice(entered_list)\n",
    "\n",
    "    data = {\n",
    "        'client_idcode': [current_pat_client_id_code] * num_rows,\n",
    "        'basicobs_itemname_analysed': [' '.join(fake.words(nb=random.randint(1, 2))) for _ in range(num_rows)],\n",
    "        'basicobs_value_numeric': [random.uniform(1, 100) for _ in range(num_rows)],\n",
    "        'basicobs_entered': [datetime(\n",
    "            random.randint(global_start_year, global_end_year),\n",
    "            random.randint(global_start_month, global_end_month),\n",
    "            random.randint(1, 28),\n",
    "            random.randint(0, 23),\n",
    "            random.randint(0, 59),\n",
    "            random.randint(0, 59)\n",
    "        ) for _ in range(num_rows)],\n",
    "        'clientvisit_serviceguid': [f'service_{i}' for i in range(num_rows)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def cohort_searcher_with_terms_and_search(index_name, fields_list, term_name, entered_list, global_start_year, global_start_month, global_end_year, global_end_month, search_string):\n",
    "    if \"basicobs_value_numeric\" in search_string:\n",
    "        num_rows = random.randint(0, 10)  # You can adjust the number of rows as needed\n",
    "        df = generate_basic_observations_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)\n",
    "        return df\n",
    "    elif index_name == \"epr_documents\":\n",
    "        num_rows = random.randint(0, 10)  # You can adjust the number of rows as needed\n",
    "        df = generate_epr_documents_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)\n",
    "        return df\n",
    "    elif index_name == \"observations\":\n",
    "        num_rows = random.randint(0, 10)  # You can adjust the number of rows as needed\n",
    "        df = generate_observations_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Index name is not 'epr_documents', 'observations', or 'basic_observations'. No data generated.\")\n",
    "        return None\n",
    "\n",
    "# Example usage for basic_observations:\n",
    "basic_observations_df = cohort_searcher_with_terms_and_search(\n",
    "    index_name=\"basic_observations\",\n",
    "    fields_list=[\"client_idcode\", \"basicobs_itemname_analysed\", \"basicobs_value_numeric\", \"basicobs_entered\", \"clientvisit_serviceguid\"],\n",
    "    term_name=\"client_idcode.keyword\",\n",
    "    entered_list=['D3232DUM23'],  # Add more client IDs as needed\n",
    "    global_start_year=2022,\n",
    "    global_start_month=1,\n",
    "    global_end_year=2023,\n",
    "    global_end_month=12,\n",
    "    search_string='basicobs_value_numeric:* AND '\n",
    "                  f'updatetime:[{global_start_year}-{global_start_month} TO {global_end_year}-{global_end_month}]'\n",
    ")\n",
    "\n",
    "display(basic_observations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_idcode</th>\n",
       "      <th>client_firstname</th>\n",
       "      <th>client_lastname</th>\n",
       "      <th>client_dob</th>\n",
       "      <th>client_gendercode</th>\n",
       "      <th>client_racecode</th>\n",
       "      <th>client_deceaseddtm</th>\n",
       "      <th>updatetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>Matthew</td>\n",
       "      <td>Gillespie</td>\n",
       "      <td>2001-04-29</td>\n",
       "      <td>male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>2022-08-09 03:38:00</td>\n",
       "      <td>2023-02-07 12:06:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>Michael</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>1974-05-30</td>\n",
       "      <td>female</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>2020-08-02 17:03:53</td>\n",
       "      <td>2022-12-05 18:04:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>Jonathan</td>\n",
       "      <td>Williams</td>\n",
       "      <td>1974-09-21</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2023-09-15 05:24:38</td>\n",
       "      <td>2022-11-23 06:30:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>Christina</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>1952-11-22</td>\n",
       "      <td>male</td>\n",
       "      <td>African American</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-07-11 03:55:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>Amber</td>\n",
       "      <td>Miller</td>\n",
       "      <td>1944-02-29</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-01-13 15:17:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>Eric</td>\n",
       "      <td>Ramirez</td>\n",
       "      <td>1967-04-02</td>\n",
       "      <td>female</td>\n",
       "      <td>African American</td>\n",
       "      <td>2023-02-19 11:06:32</td>\n",
       "      <td>2022-03-23 02:00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Wilkinson</td>\n",
       "      <td>1977-12-24</td>\n",
       "      <td>male</td>\n",
       "      <td>African American</td>\n",
       "      <td>2021-10-03 20:09:52</td>\n",
       "      <td>2023-11-26 12:05:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>Dennis</td>\n",
       "      <td>Smith</td>\n",
       "      <td>1944-03-24</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2022-03-06 06:39:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>Brian</td>\n",
       "      <td>Reeves</td>\n",
       "      <td>1976-06-07</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2023-10-22 16:02:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  client_idcode client_firstname client_lastname  client_dob  \\\n",
       "0    D3232DUM23          Matthew       Gillespie  2001-04-29   \n",
       "1    D3232DUM23          Michael        Campbell  1974-05-30   \n",
       "2    D3232DUM23         Jonathan        Williams  1974-09-21   \n",
       "3    D3232DUM23        Christina         Johnson  1952-11-22   \n",
       "4    D3232DUM23            Amber          Miller  1944-02-29   \n",
       "5    D3232DUM23             Eric         Ramirez  1967-04-02   \n",
       "6    D3232DUM23         Victoria       Wilkinson  1977-12-24   \n",
       "7    D3232DUM23           Dennis           Smith  1944-03-24   \n",
       "8    D3232DUM23            Brian          Reeves  1976-06-07   \n",
       "\n",
       "  client_gendercode   client_racecode  client_deceaseddtm          updatetime  \n",
       "0              male         Caucasian 2022-08-09 03:38:00 2023-02-07 12:06:25  \n",
       "1            female         Caucasian 2020-08-02 17:03:53 2022-12-05 18:04:25  \n",
       "2            female             Asian 2023-09-15 05:24:38 2022-11-23 06:30:43  \n",
       "3              male  African American                 NaT 2022-07-11 03:55:51  \n",
       "4              male             Asian                 NaT 2023-01-13 15:17:35  \n",
       "5            female  African American 2023-02-19 11:06:32 2022-03-23 02:00:03  \n",
       "6              male  African American 2021-10-03 20:09:52 2023-11-26 12:05:07  \n",
       "7            female             Asian                 NaT 2022-03-06 06:39:08  \n",
       "8            female             Asian                 NaT 2023-10-22 16:02:36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_epr_documents_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    current_pat_client_id_code = random.choice(entered_list)\n",
    "    \n",
    "    data = {\n",
    "        'client_idcode': [random.choice(entered_list) for _ in range(num_rows)],\n",
    "        'document_guid': [f'doc_{i}' for i in range(num_rows)],\n",
    "        'document_description': [f'description_{i}' for i in range(num_rows)],\n",
    "        'body_analysed': [fake.paragraph() for _ in range(num_rows)],\n",
    "        'updatetime': [datetime(\n",
    "            random.randint(global_start_year, global_end_year),\n",
    "            random.randint(global_start_month, global_end_month),\n",
    "            random.randint(1, 28),\n",
    "            random.randint(0, 23),\n",
    "            random.randint(0, 59),\n",
    "            random.randint(0, 59)\n",
    "        ) for _ in range(num_rows)],\n",
    "        'clientvisit_visitidcode': [f'visit_{i}' for i in range(num_rows)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def generate_epr_documents_personal_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    current_pat_client_id_code = random.choice(entered_list)\n",
    "\n",
    "    data = {\n",
    "        'client_idcode': [current_pat_client_id_code] * num_rows,\n",
    "        'client_firstname': [fake.first_name() for _ in range(num_rows)],\n",
    "        'client_lastname': [fake.last_name() for _ in range(num_rows)],\n",
    "        'client_dob': [fake.date_of_birth(minimum_age=18, maximum_age=90).strftime('%Y-%m-%d') for _ in range(num_rows)],\n",
    "        'client_gendercode': [random.choice(['male', 'female']) for _ in range(num_rows)],\n",
    "        'client_racecode': [fake.random_element(['Caucasian', 'African American', 'Hispanic', 'Asian', 'Other']) for _ in range(num_rows)],\n",
    "        'client_deceaseddtm': [fake.date_time_this_decade() if random.choice([True, False]) else None for _ in range(num_rows)],\n",
    "        'updatetime': [datetime(\n",
    "            random.randint(global_start_year, global_end_year),\n",
    "            random.randint(global_start_month, global_end_month),\n",
    "            random.randint(1, 28),\n",
    "            random.randint(0, 23),\n",
    "            random.randint(0, 59),\n",
    "            random.randint(0, 59)\n",
    "        ) for _ in range(num_rows)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def generate_observations_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    current_pat_client_id_code = random.choice(entered_list)\n",
    "    \n",
    "    data = {\n",
    "        'observation_guid': [f'obs_{i}' for i in range(num_rows)],\n",
    "        'client_idcode': [random.choice(entered_list) for _ in range(num_rows)],\n",
    "        'obscatalogmasteritem_displayname': 'AoMRC_ClinicalSummary_FT',\n",
    "        'observation_valuetext_analysed': [fake.paragraph() for _ in range(num_rows)],\n",
    "        'observationdocument_recordeddtm': [datetime(\n",
    "            random.randint(global_start_year, global_end_year),\n",
    "            random.randint(global_start_month, global_end_month),\n",
    "            random.randint(1, 28),\n",
    "            random.randint(0, 23),\n",
    "            random.randint(0, 59),\n",
    "            random.randint(0, 59)\n",
    "        ) for _ in range(num_rows)],\n",
    "        'clientvisit_visitidcode': [f'visit_{i}' for i in range(num_rows)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def generate_basic_observations_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month):\n",
    "    current_pat_client_id_code = random.choice(entered_list)\n",
    "\n",
    "    data = {\n",
    "        'client_idcode': [current_pat_client_id_code] * num_rows,\n",
    "        'basicobs_itemname_analysed': [' '.join(fake.words(nb=random.randint(1, 2))) for _ in range(num_rows)],\n",
    "        'basicobs_value_numeric': [random.uniform(1, 100) for _ in range(num_rows)],\n",
    "        'basicobs_entered': [datetime(\n",
    "            random.randint(global_start_year, global_end_year),\n",
    "            random.randint(global_start_month, global_end_month),\n",
    "            random.randint(1, 28),\n",
    "            random.randint(0, 23),\n",
    "            random.randint(0, 59),\n",
    "            random.randint(0, 59)\n",
    "        ) for _ in range(num_rows)],\n",
    "        'clientvisit_serviceguid': [f'service_{i}' for i in range(num_rows)]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def cohort_searcher_with_terms_and_search_dummy(index_name, fields_list, term_name, entered_list, global_start_year, global_start_month, global_end_year, global_end_month, search_string):\n",
    "    if \"client_firstname\" in fields_list:\n",
    "        num_rows = random.randint(0, 10)  # You can adjust the number of rows as needed\n",
    "        df = generate_epr_documents_personal_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)\n",
    "        return df\n",
    "    elif \"basicobs_value_numeric\" in search_string:\n",
    "        num_rows = random.randint(0, 10)  # You can adjust the number of rows as needed\n",
    "        df = generate_basic_observations_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)\n",
    "        return df\n",
    "    elif index_name == \"epr_documents\":\n",
    "        num_rows = random.randint(0, 10)  # You can adjust the number of rows as needed\n",
    "        df = generate_epr_documents_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)\n",
    "        return df\n",
    "    elif index_name == \"observations\":\n",
    "        num_rows = random.randint(0, 10)  # You can adjust the number of rows as needed\n",
    "        df = generate_observations_data(num_rows, entered_list, global_start_year, global_start_month, global_end_year, global_end_month)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Index name is not 'epr_documents', 'observations', 'basic_observations'. Returning an empty DataFrame.\")\n",
    "        return pd.DataFrame(columns=['updatetime'] + fields_list)\n",
    "\n",
    "\n",
    "# Example usage for epr_documents with personal information:\n",
    "epr_documents_personal_df = cohort_searcher_with_terms_and_search_dummy(\n",
    "    index_name=\"epr_documents\",\n",
    "    fields_list=[\"client_idcode\", \"client_firstname\", \"client_lastname\", \"client_dob\", \"client_gendercode\", \"client_racecode\", \"client_deceaseddtm\", \"updatetime\"],\n",
    "    term_name=\"client_idcode.keyword\",\n",
    "    entered_list=['D3232DUM23'],  # Add more client IDs as needed\n",
    "    global_start_year=2022,\n",
    "    global_start_month=1,\n",
    "    global_end_year=2023,\n",
    "    global_end_month=12,\n",
    "    search_string=f'updatetime:[{global_start_year}-{global_start_month} TO {global_end_year}-{global_end_month}]'\n",
    ")\n",
    "\n",
    "display(epr_documents_personal_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_idcode</th>\n",
       "      <th>document_guid</th>\n",
       "      <th>document_description</th>\n",
       "      <th>body_analysed</th>\n",
       "      <th>updatetime</th>\n",
       "      <th>clientvisit_visitidcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_0</td>\n",
       "      <td>description_0</td>\n",
       "      <td>Mean weight yes positive stand report democrat...</td>\n",
       "      <td>2022-12-05 01:12:55</td>\n",
       "      <td>visit_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_1</td>\n",
       "      <td>description_1</td>\n",
       "      <td>South generation win agency market trouble lan...</td>\n",
       "      <td>2023-07-07 16:53:33</td>\n",
       "      <td>visit_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_2</td>\n",
       "      <td>description_2</td>\n",
       "      <td>Stop return class. Forget number out chair fro...</td>\n",
       "      <td>2023-02-17 04:16:48</td>\n",
       "      <td>visit_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D3232DUM23</td>\n",
       "      <td>doc_3</td>\n",
       "      <td>description_3</td>\n",
       "      <td>Then skill the stay. Mouth age lot energy.</td>\n",
       "      <td>2023-11-17 11:21:45</td>\n",
       "      <td>visit_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  client_idcode document_guid document_description  \\\n",
       "0    D3232DUM23         doc_0        description_0   \n",
       "1    D3232DUM23         doc_1        description_1   \n",
       "2    D3232DUM23         doc_2        description_2   \n",
       "3    D3232DUM23         doc_3        description_3   \n",
       "\n",
       "                                       body_analysed          updatetime  \\\n",
       "0  Mean weight yes positive stand report democrat... 2022-12-05 01:12:55   \n",
       "1  South generation win agency market trouble lan... 2023-07-07 16:53:33   \n",
       "2  Stop return class. Forget number out chair fro... 2023-02-17 04:16:48   \n",
       "3         Then skill the stay. Mouth age lot energy. 2023-11-17 11:21:45   \n",
       "\n",
       "  clientvisit_visitidcode  \n",
       "0                 visit_0  \n",
       "1                 visit_1  \n",
       "2                 visit_2  \n",
       "3                 visit_3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_df = cohort_searcher_with_terms_and_search_dummy(\n",
    "    index_name=\"epr_documents\",\n",
    "    fields_list=\"\"\"client_idcode document_guid document_description body_analysed updatetime clientvisit_visitidcode\"\"\".split(),\n",
    "    term_name=\"client_idcode.keyword\",\n",
    "    entered_list=['D3232DUM23'],  # Add more client IDs as needed\n",
    "    global_start_year=2022,\n",
    "    global_start_month=1,\n",
    "    global_end_year=2023,\n",
    "    global_end_month=12,\n",
    "    search_string=''\n",
    ")\n",
    "\n",
    "display(dummy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
